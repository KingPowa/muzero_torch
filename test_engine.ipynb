{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym as g\n",
    "from gym import spaces\n",
    "from connect4 import *\n",
    "from envs import ConnectNEnv\n",
    "from networks.architecture import RepresentationNetwork, DynamicsNetwork, PredictionNetwork\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.engine import *\n",
    "from architecture.network import MuZeroNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "muzeronet = MuZeroNetwork(3, 42, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8164, 0.3978, 0.5306, 0.7621, 0.6582, 0.9760, 0.9334],\n",
      "          [0.7042, 0.7333, 0.5411, 0.4834, 0.8974, 0.8145, 0.9633],\n",
      "          [0.0543, 0.8457, 0.8538, 0.9461, 0.5980, 0.2447, 0.8905],\n",
      "          [0.1447, 0.6893, 0.7165, 0.2817, 0.7685, 0.0572, 0.3851],\n",
      "          [0.9205, 0.3805, 0.7149, 0.2021, 0.1950, 0.6012, 0.4564],\n",
      "          [0.5681, 0.0198, 0.1473, 0.3247, 0.9509, 0.5057, 0.1253]],\n",
      "\n",
      "         [[0.1627, 0.4590, 0.7942, 0.7758, 0.4085, 0.8357, 0.0628],\n",
      "          [0.1283, 0.7485, 0.3682, 0.2006, 0.5233, 0.4437, 0.8897],\n",
      "          [0.7680, 0.4537, 0.4231, 0.5720, 0.8746, 0.1214, 0.1399],\n",
      "          [0.2545, 0.7950, 0.8608, 0.9635, 0.7578, 0.8966, 0.1168],\n",
      "          [0.6715, 0.5328, 0.6477, 0.7215, 0.1433, 0.7837, 0.8096],\n",
      "          [0.1592, 0.0315, 0.1015, 0.1938, 0.3604, 0.0491, 0.4752]],\n",
      "\n",
      "         [[0.8990, 0.1772, 0.1149, 0.0940, 0.5202, 0.1769, 0.0163],\n",
      "          [0.2009, 0.8592, 0.5997, 0.4336, 0.9139, 0.9262, 0.8298],\n",
      "          [0.6779, 0.1890, 0.9911, 0.3530, 0.6501, 0.9422, 0.9426],\n",
      "          [0.0576, 0.4454, 0.4264, 0.1100, 0.0764, 0.1918, 0.1826],\n",
      "          [0.1478, 0.8202, 0.2951, 0.7868, 0.3562, 0.9130, 0.2418],\n",
      "          [0.0554, 0.1303, 0.6253, 0.0387, 0.1562, 0.2043, 0.9295]]]])\n"
     ]
    }
   ],
   "source": [
    "# Test representation\n",
    "image = torch.rand((1,3,6,7))\n",
    "print(image)\n",
    "encoded_state = muzeronet.representation(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.]]) torch.Size([1, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[4.3214e-01, 4.0599e-02, 2.8226e-01,  ..., 1.1668e-01,\n",
       "            0.0000e+00, 1.3287e-01],\n",
       "           [4.7820e-01, 5.1756e-01, 4.1466e-01,  ..., 3.9560e-01,\n",
       "            7.6381e-02, 3.6691e-01],\n",
       "           [4.4407e-02, 1.5847e-01, 0.0000e+00,  ..., 7.5680e-01,\n",
       "            5.7044e-01, 8.8602e-01],\n",
       "           [3.5920e-01, 2.5235e-01, 1.0000e+00,  ..., 7.9974e-01,\n",
       "            8.2152e-02, 5.0499e-02],\n",
       "           [3.7395e-01, 1.9091e-01, 0.0000e+00,  ..., 7.5617e-01,\n",
       "            0.0000e+00, 1.5508e-01],\n",
       "           [3.9213e-01, 3.3644e-01, 0.0000e+00,  ..., 5.4355e-01,\n",
       "            2.6583e-01, 6.9747e-01]],\n",
       " \n",
       "          [[6.1616e-02, 6.5698e-01, 7.0193e-02,  ..., 5.4003e-01,\n",
       "            6.0881e-01, 3.5305e-01],\n",
       "           [5.8537e-02, 6.2559e-01, 9.0076e-02,  ..., 2.5636e-01,\n",
       "            2.7658e-01, 9.9618e-02],\n",
       "           [0.0000e+00, 0.0000e+00, 3.3487e-01,  ..., 2.6932e-01,\n",
       "            4.2478e-01, 2.2559e-01],\n",
       "           [5.4717e-04, 1.4172e-01, 4.7592e-01,  ..., 5.8897e-01,\n",
       "            4.1547e-01, 4.6722e-01],\n",
       "           [0.0000e+00, 2.8264e-01, 2.9257e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 3.8847e-01],\n",
       "           [0.0000e+00, 6.6259e-02, 1.0250e-01,  ..., 4.9741e-03,\n",
       "            1.2026e-01, 6.1806e-02]],\n",
       " \n",
       "          [[1.4787e-01, 1.4481e-01, 2.6591e-01,  ..., 7.7243e-02,\n",
       "            4.8185e-01, 4.1602e-01],\n",
       "           [5.4531e-01, 4.9002e-02, 1.6644e-01,  ..., 2.0145e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [0.0000e+00, 4.8057e-01, 3.7889e-01,  ..., 0.0000e+00,\n",
       "            3.9869e-01, 0.0000e+00],\n",
       "           [3.1951e-01, 5.7451e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "            1.9898e-01, 1.3094e-01],\n",
       "           [1.8594e-01, 3.5364e-01, 3.6348e-01,  ..., 2.0241e-01,\n",
       "            1.2911e-01, 2.8481e-01],\n",
       "           [1.9920e-01, 3.9602e-02, 2.5730e-01,  ..., 4.4455e-01,\n",
       "            4.1708e-01, 8.2536e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[2.1234e-02, 0.0000e+00, 6.6273e-01,  ..., 3.5803e-01,\n",
       "            2.9113e-01, 2.3986e-01],\n",
       "           [0.0000e+00, 3.0631e-01, 6.0991e-02,  ..., 0.0000e+00,\n",
       "            9.2060e-02, 0.0000e+00],\n",
       "           [4.2079e-01, 3.9260e-01, 4.3534e-01,  ..., 9.1561e-03,\n",
       "            1.6524e-01, 1.5213e-01],\n",
       "           [2.3023e-01, 0.0000e+00, 4.6815e-01,  ..., 6.2391e-01,\n",
       "            2.0477e-01, 4.2187e-01],\n",
       "           [5.2052e-01, 0.0000e+00, 1.7550e-01,  ..., 3.2784e-03,\n",
       "            5.7482e-01, 4.6493e-01],\n",
       "           [1.2978e-01, 1.7483e-01, 3.3269e-02,  ..., 0.0000e+00,\n",
       "            5.2958e-01, 1.5735e-01]],\n",
       " \n",
       "          [[3.2776e-01, 0.0000e+00, 2.1444e-01,  ..., 4.2547e-01,\n",
       "            3.0033e-01, 2.2028e-01],\n",
       "           [4.9477e-02, 2.3969e-01, 7.3481e-01,  ..., 1.1612e-01,\n",
       "            3.4141e-01, 1.0000e+00],\n",
       "           [2.9998e-01, 5.4075e-01, 5.0027e-02,  ..., 2.6137e-01,\n",
       "            4.6603e-01, 5.3027e-01],\n",
       "           [6.4342e-02, 0.0000e+00, 1.3083e-01,  ..., 0.0000e+00,\n",
       "            3.8679e-01, 4.9459e-01],\n",
       "           [5.4999e-02, 8.9199e-01, 4.2882e-02,  ..., 3.9224e-01,\n",
       "            0.0000e+00, 2.1273e-01],\n",
       "           [6.0057e-02, 9.6014e-02, 9.5181e-02,  ..., 1.1809e-01,\n",
       "            1.1949e-01, 0.0000e+00]],\n",
       " \n",
       "          [[2.4917e-01, 2.9347e-01, 3.4094e-01,  ..., 2.9852e-01,\n",
       "            5.3890e-01, 2.7199e-01],\n",
       "           [1.2496e-01, 0.0000e+00, 5.4579e-01,  ..., 2.8891e-01,\n",
       "            0.0000e+00, 1.7515e-01],\n",
       "           [3.8946e-01, 9.3278e-01, 3.7443e-02,  ..., 0.0000e+00,\n",
       "            1.0000e+00, 1.0491e-01],\n",
       "           [2.4294e-01, 7.1195e-01, 1.1693e-01,  ..., 7.1270e-01,\n",
       "            0.0000e+00, 2.3340e-01],\n",
       "           [7.9792e-02, 9.2706e-01, 4.4916e-02,  ..., 0.0000e+00,\n",
       "            4.2332e-01, 1.5341e-01],\n",
       "           [4.3400e-01, 0.0000e+00, 3.9581e-01,  ..., 2.5523e-01,\n",
       "            5.4486e-01, 3.9663e-01]]]], grad_fn=<DivBackward0>),\n",
       " tensor([[ 5.0561e-02,  5.3336e-01, -2.7899e-01, -3.5560e-01,  2.9825e-03,\n",
       "          -5.9539e-01, -7.7082e-01, -4.4961e-01,  5.2392e-01,  4.7053e-01,\n",
       "           1.1589e-01, -4.1815e-01,  4.6045e-02,  1.5425e-01, -1.7567e-01,\n",
       "           6.8360e-02, -3.1245e-03, -5.2358e-01, -2.6853e-02,  6.9224e-02,\n",
       "          -1.4925e-01, -6.9384e-01, -5.0127e-01,  1.0345e+00, -3.3773e-01,\n",
       "           7.4477e-01,  9.5445e-02, -1.3026e-01, -8.2850e-01, -5.1871e-02,\n",
       "           2.1570e-01,  3.8295e-01, -2.6892e-01,  5.6836e-01,  5.5592e-01,\n",
       "          -5.5743e-02,  4.0818e-02,  2.5575e-01, -7.3761e-01,  9.9791e-02,\n",
       "           5.4127e-01,  1.6384e-02,  3.7732e-01,  4.3837e-01, -6.5212e-01,\n",
       "           2.6994e-01, -4.7469e-01, -4.5507e-01, -3.0686e-01, -2.0085e-01,\n",
       "           3.1883e-01,  5.4088e-01, -2.1351e-01,  1.0659e-01, -7.6626e-01,\n",
       "          -3.1791e-02, -3.3709e-01, -3.1694e-01,  5.7907e-01, -2.8562e-01,\n",
       "          -2.6317e-01, -1.5430e-03, -7.3857e-02, -9.5357e-02, -1.0707e-01,\n",
       "           3.0204e-01,  1.2037e-01, -9.1029e-02,  8.9056e-01,  3.3451e-02,\n",
       "          -3.5236e-01, -1.1005e+00, -4.5221e-01,  1.5938e-01, -4.9150e-02,\n",
       "           2.5869e-01,  6.6487e-01,  1.3687e-01, -9.2062e-01, -8.2093e-01,\n",
       "          -8.3324e-01,  2.8371e-01, -3.5157e-01,  4.4304e-02,  6.4661e-02,\n",
       "           4.7542e-01, -6.7632e-01,  2.3994e-01,  4.9355e-02, -4.1278e-02,\n",
       "           2.7995e-01,  5.8368e-01,  6.8307e-02, -4.7807e-01, -2.7232e-01,\n",
       "          -1.5620e-01,  3.5398e-01, -8.4366e-02, -2.6310e-01,  5.8592e-01,\n",
       "           3.0936e-01,  4.6177e-01, -1.5035e-01,  2.9582e-01, -4.4898e-02,\n",
       "          -1.0431e-01,  2.6762e-01,  1.2553e-02, -4.7878e-01, -3.1869e-01,\n",
       "           3.9931e-01,  4.1840e-01,  2.6518e-01, -7.6674e-02,  2.8954e-02,\n",
       "           7.7259e-02, -2.3176e-01, -5.2239e-01,  3.6920e-01,  1.1326e-01,\n",
       "           3.8818e-02, -6.5383e-01, -7.6827e-01,  1.8237e-02,  3.9859e-01,\n",
       "           5.0728e-01, -2.5146e-01, -5.9371e-01,  2.7319e-01, -1.6547e-01,\n",
       "          -3.9350e-01, -8.1587e-01,  6.7015e-01, -4.7853e-01,  3.3594e-02,\n",
       "          -9.1150e-01, -1.1925e-01,  2.3741e-01, -2.5770e-01, -3.0343e-02,\n",
       "          -2.1955e-01, -8.2158e-01, -2.2813e-01, -1.3981e-01, -2.0464e-01,\n",
       "          -1.5285e-01,  4.0404e-01,  6.9312e-01, -5.4134e-01, -2.4719e-01,\n",
       "           1.0989e+00, -1.8856e-01, -9.4208e-01,  1.5982e-01, -1.6814e-01,\n",
       "          -6.0615e-01,  3.2267e-02, -6.9452e-01,  1.0972e-01,  1.8273e-01,\n",
       "          -6.6266e-01,  2.9866e-01, -1.4479e-01, -7.8010e-01,  4.2148e-01,\n",
       "          -2.1687e-01, -4.1282e-02,  2.7213e-01,  2.1424e-01, -1.2339e-01,\n",
       "          -7.4084e-02,  1.7542e-01,  2.9057e-01,  3.0879e-01, -2.8758e-01,\n",
       "          -3.2451e-01,  4.8265e-01,  6.3086e-01, -2.3762e-01,  5.3996e-01,\n",
       "           1.8207e-01, -4.6420e-01,  8.8024e-01, -3.4340e-01, -3.2418e-01,\n",
       "           2.3190e-01, -1.0002e+00, -1.5742e-01,  4.1256e-01, -2.0148e-01,\n",
       "           2.7668e-02,  7.6488e-03, -5.8669e-01, -1.6466e-01, -7.2508e-02,\n",
       "          -4.0648e-01,  2.7294e-01, -1.9509e-01,  4.1767e-01,  5.2479e-01,\n",
       "           2.0317e-01, -1.2695e-01, -6.1282e-02,  1.0721e-01, -5.8311e-02,\n",
       "           2.5003e-01,  1.3964e-01, -9.6120e-01,  4.8221e-01, -4.5605e-01,\n",
       "           5.3194e-01,  6.0086e-02, -1.1234e-01,  2.8210e-02,  3.3104e-01,\n",
       "          -7.2253e-01, -7.4634e-02, -4.3040e-01, -7.0648e-01, -4.2596e-01,\n",
       "          -3.0993e-01,  2.9278e-01, -3.9688e-01, -1.0288e+00,  5.7155e-02,\n",
       "          -2.7879e-01,  4.4366e-01,  2.1546e-01,  6.0197e-01, -2.3365e-01,\n",
       "           3.3104e-01,  1.0825e+00, -5.9327e-01,  6.4199e-01, -4.0138e-01,\n",
       "           5.7512e-01,  1.6596e-01, -6.8720e-01, -2.1088e-02, -3.4165e-02,\n",
       "           8.8718e-02, -4.8651e-02, -6.7573e-01,  2.6938e-01, -4.5497e-01,\n",
       "          -2.0110e-01,  3.8067e-02, -3.7439e-01, -4.0017e-01, -5.0122e-01,\n",
       "          -4.2942e-03,  5.3816e-01,  4.1983e-01,  2.8970e-01,  7.5374e-02,\n",
       "          -3.8149e-01,  2.7833e-01,  2.0413e-01, -1.5950e-01, -3.5976e-01,\n",
       "           3.4369e-02, -2.5677e-02, -2.0460e-02,  6.2810e-02,  5.1263e-02,\n",
       "           3.1015e-01,  2.5574e-01, -3.1855e-01, -4.1145e-01,  7.6912e-02,\n",
       "          -1.1050e-02,  5.8279e-02,  4.1724e-02, -5.4122e-02,  1.0468e-01,\n",
       "           1.9713e-02, -7.9415e-01, -4.4944e-01, -1.0845e-03,  6.3372e-01,\n",
       "           9.1386e-01, -1.2185e-01,  6.1651e-03,  7.5275e-01,  1.3373e-01,\n",
       "           4.6856e-02, -2.7333e-01,  1.4027e-01, -1.9005e-01, -5.8291e-02,\n",
       "           2.6351e-01,  6.9274e-01,  5.9034e-01,  7.4234e-01, -4.5658e-01,\n",
       "          -2.9806e-01,  5.9542e-01, -7.1086e-02, -1.4967e-01,  3.2762e-02,\n",
       "          -6.3603e-01, -3.1339e-01, -5.8573e-01, -3.6996e-01,  4.6804e-01,\n",
       "           2.3547e-01,  5.0017e-02,  3.8174e-01,  6.3178e-02, -1.8551e-01,\n",
       "           4.9887e-01,  1.6548e-01,  3.2986e-01, -4.3495e-01,  3.4559e-01,\n",
       "          -1.5543e-01, -3.2091e-01, -1.1958e-01,  1.8762e-01,  4.8954e-01,\n",
       "           2.1234e-01,  2.2710e-01,  4.3194e-01, -5.7477e-01, -1.0707e-01,\n",
       "           2.1210e-01, -3.8730e-01, -1.0328e-01, -6.9069e-01,  2.0269e-02,\n",
       "          -3.4653e-01, -7.3620e-01, -4.3632e-01, -2.4902e-01,  4.5207e-01,\n",
       "          -4.0844e-01, -1.8052e-02,  1.8831e-01,  1.4594e-01, -2.8085e-01,\n",
       "           6.8488e-01,  8.5210e-01, -1.3911e-01, -3.3121e-01, -2.7557e-01,\n",
       "          -4.5504e-02, -4.5751e-01, -1.9531e-01, -5.8521e-01,  2.6869e-01,\n",
       "           1.8649e-01, -2.7941e-02, -4.3982e-01, -2.3311e-01,  5.7516e-01,\n",
       "           2.8626e-01, -3.0929e-01, -5.7471e-01,  2.3501e-02,  7.4118e-01,\n",
       "          -5.4532e-01, -4.6571e-01,  1.7783e-01,  4.2926e-01, -4.5734e-01,\n",
       "           7.2885e-02, -3.9915e-03,  4.0146e-01,  2.0750e-01, -4.6196e-01,\n",
       "           7.4808e-01, -5.5523e-01, -2.7554e-01,  3.4341e-01, -7.0351e-01,\n",
       "          -1.3452e-01,  1.1867e-01, -3.9319e-01, -4.2836e-01,  4.2477e-01,\n",
       "           4.0953e-01,  2.7655e-01, -7.4133e-01,  1.3005e-01, -3.8928e-01,\n",
       "          -2.4857e-01,  1.1962e-01,  7.3087e-02, -8.1079e-02,  4.2657e-01,\n",
       "           7.4765e-01,  1.7953e-02,  2.5179e-01,  2.7001e-01,  3.2011e-01,\n",
       "          -1.8641e-02,  6.9575e-02, -7.3014e-01,  4.9652e-02,  2.2134e-01,\n",
       "           4.0537e-01,  1.0807e-01, -3.6387e-01, -8.6442e-02, -5.6043e-01,\n",
       "          -2.7562e-01,  6.4425e-01, -2.8052e-01, -3.2678e-01,  4.5398e-01,\n",
       "           1.0281e-02,  5.0204e-01,  3.7546e-01, -3.2843e-01, -9.6976e-02,\n",
       "          -1.9217e-01,  5.4508e-01, -3.8391e-01,  6.0815e-02,  1.0489e-01,\n",
       "          -5.5044e-02,  3.4401e-01, -3.8084e-01, -9.9835e-02,  5.6141e-01,\n",
       "           1.1022e-01, -4.0815e-01,  2.4008e-01, -6.6149e-01,  3.9566e-01,\n",
       "          -5.2377e-01, -1.2257e-01, -3.2092e-01, -3.9838e-01,  8.7309e-01,\n",
       "          -4.0147e-01,  5.3238e-01, -2.7078e-01,  2.5874e-01,  2.4725e-02,\n",
       "          -3.1758e-01, -8.5081e-02, -6.8760e-01, -3.2542e-01,  1.0529e-01,\n",
       "          -7.4236e-02, -5.0038e-01,  1.4787e-01, -1.6618e-01,  4.5965e-01,\n",
       "          -5.9442e-02,  4.1010e-01, -2.2688e-01,  9.9609e-02,  3.9729e-01,\n",
       "           1.8079e-01, -1.7579e-01, -2.0806e-01,  1.2513e-01,  1.6585e-01,\n",
       "           3.2745e-01,  6.3754e-01, -1.0465e+00, -2.1099e-01,  7.6499e-01,\n",
       "           1.3974e-01, -1.9908e-01, -3.1360e-01,  5.2803e-01, -5.0856e-01,\n",
       "          -3.8454e-02,  3.9137e-01, -1.0914e-01, -4.0320e-01, -1.6991e-01,\n",
       "           1.9188e-01, -1.2614e-01,  3.2153e-01, -1.5702e-01, -5.2662e-01,\n",
       "          -5.2581e-01, -2.3013e-01,  5.8308e-01,  2.7655e-01,  4.8292e-02,\n",
       "          -1.4301e-01, -4.2864e-02, -5.2964e-03,  2.0591e-01, -3.2545e-01,\n",
       "           1.1695e-01, -4.1070e-02, -9.3371e-01, -1.5154e-01,  4.8800e-02,\n",
       "          -1.3469e-01,  2.1345e-01, -4.0933e-02, -4.6057e-02, -7.1039e-02,\n",
       "          -1.8783e-01, -2.0877e-01, -2.2163e-01, -2.4408e-01,  6.2478e-02,\n",
       "           1.5848e-01,  7.9889e-02, -7.4453e-01,  1.0095e-01, -5.9262e-01,\n",
       "          -3.0514e-01, -7.3527e-01,  2.4021e-01, -1.8305e-01, -2.0755e-01,\n",
       "          -4.7852e-01, -1.7201e-01, -2.7383e-02, -5.3305e-02,  4.4311e-02,\n",
       "          -1.4485e-01, -5.8009e-01,  4.1019e-01,  4.1945e-01,  2.6742e-01,\n",
       "           6.2456e-01,  1.5896e-01, -3.7830e-01, -2.8916e-01, -1.2654e-01,\n",
       "          -4.8970e-02, -1.0687e-01,  2.0396e-01,  3.8667e-02,  4.3895e-02,\n",
       "          -4.5306e-01,  4.0567e-01, -8.9957e-02,  1.2625e-01,  1.2681e-01,\n",
       "          -9.8211e-01, -6.8356e-03,  2.2480e-01,  2.9078e-01, -3.5225e-01,\n",
       "           1.0286e-01, -2.2075e-01, -1.6442e-01, -4.1706e-01,  4.0630e-02,\n",
       "          -7.8830e-03, -7.8752e-01,  7.9668e-01,  6.7601e-01, -4.4848e-01,\n",
       "           3.4785e-02, -3.2470e-02,  5.2361e-01,  4.0295e-01,  3.5508e-01,\n",
       "           8.6614e-02, -1.7184e-01, -1.0385e-01, -7.3827e-02, -5.5167e-02,\n",
       "           3.0177e-02, -6.0557e-02,  1.7278e-02, -2.5708e-01,  5.6159e-01,\n",
       "          -4.1243e-01,  4.8532e-01,  1.0021e-01,  7.6773e-01,  1.3349e-01,\n",
       "          -1.4838e-01,  1.3032e+00,  1.0120e-01, -2.6783e-01,  1.2803e-01,\n",
       "           1.7686e-01, -2.6742e-01,  1.7122e-01, -2.9960e-01, -6.1979e-01,\n",
       "           2.9736e-01,  2.9383e-01, -3.7555e-01, -3.2471e-02, -1.9001e-01,\n",
       "          -2.2866e-01, -4.2090e-01,  2.2837e-01, -1.2745e-01, -9.8509e-02,\n",
       "          -9.9204e-02,  2.4940e-02,  9.6827e-03,  3.4147e-01,  7.0409e-01,\n",
       "           3.2386e-01]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dynamics\n",
    "action = torch.Tensor([2]).view(1,1)\n",
    "print(action, action.shape)\n",
    "muzeronet.dynamics(encoded_state=encoded_state, action=action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.8739e-01, -4.1028e-01, -4.9489e-01,  4.8979e-01, -2.4874e-01,\n",
       "          -2.8344e-01,  3.9383e-01,  2.0841e-02,  1.2388e-01, -1.4315e-01,\n",
       "          -3.6518e-01, -4.2270e-01,  2.3656e-02,  2.7098e-01, -1.5509e-01,\n",
       "           2.3380e-01, -8.8022e-01, -1.8085e-01, -3.7263e-01,  5.7183e-01,\n",
       "          -3.0691e-01, -4.4679e-01,  1.0563e-01, -3.3149e-01,  6.1416e-01,\n",
       "          -1.5688e-01,  3.1850e-01, -6.4031e-01,  8.1237e-01,  4.7470e-01,\n",
       "           1.1176e+00, -2.6204e-01,  4.1129e-01,  1.5288e-01,  6.6225e-01,\n",
       "          -3.9296e-01, -1.1490e-02, -2.3583e-02,  2.2654e-01, -4.8640e-02,\n",
       "           8.4233e-02,  7.5906e-01, -2.3497e-01,  4.1439e-01,  4.0514e-02,\n",
       "           1.0399e-01, -3.1816e-02,  6.6869e-02,  2.8041e-01,  1.2584e-01,\n",
       "           3.2183e-01, -5.6122e-02, -4.8337e-01, -2.8260e-01, -2.2473e-01,\n",
       "          -2.4019e-01, -2.9997e-01, -1.9957e-01,  6.8398e-02,  2.1050e-01,\n",
       "          -5.3910e-01,  4.6702e-01,  3.7780e-01,  6.5241e-01,  4.8683e-01,\n",
       "           7.4357e-01, -8.0650e-02,  6.0261e-02, -2.4641e-01,  1.6211e-01,\n",
       "           1.0454e-01,  3.1035e-01,  3.6765e-01,  1.5181e-01, -8.9125e-01,\n",
       "          -2.2892e-01,  5.5699e-02,  6.4779e-03,  2.5128e-01, -7.3606e-01,\n",
       "           6.2263e-01, -1.0911e-01, -8.9599e-02,  1.2601e-01, -6.7540e-01,\n",
       "           1.9721e-01,  4.1114e-01, -1.2495e-01, -1.8232e-01,  3.5637e-01,\n",
       "          -6.2438e-01, -2.4214e-01,  1.4636e-01, -3.1278e-01, -5.2265e-01,\n",
       "          -6.0528e-01,  2.6884e-01, -6.6047e-02, -4.7524e-01,  3.8985e-01,\n",
       "          -4.5944e-01,  1.1261e-01, -5.0077e-01,  3.2633e-01, -1.9149e-01,\n",
       "           9.6017e-01,  4.0874e-01,  8.8273e-01,  4.6354e-01,  3.5080e-01,\n",
       "          -1.2716e-01, -6.5460e-01, -8.2410e-02,  3.4687e-01, -1.7844e-01,\n",
       "           7.3726e-01, -6.5235e-02, -4.4652e-01,  1.0368e+00, -2.8765e-01,\n",
       "          -4.4062e-01, -4.4549e-01,  4.1474e-01,  5.5243e-01,  3.0358e-01,\n",
       "           1.5721e-01,  1.3605e-01, -8.8240e-01, -3.2600e-01, -2.3283e-01,\n",
       "          -2.7597e-01,  5.6743e-01,  1.3461e-01, -3.3065e-03, -4.6643e-01,\n",
       "          -2.2687e-01, -1.6007e-01,  2.9832e-01, -5.3341e-01,  5.0748e-01,\n",
       "           6.2986e-02,  2.0889e-02,  3.9420e-01,  4.9892e-01, -6.7007e-02,\n",
       "          -9.6472e-02, -5.7708e-01, -4.3998e-01,  1.2978e-01,  8.9476e-02,\n",
       "           4.0144e-01,  6.5081e-01, -8.7856e-02,  2.0789e-01,  1.0172e-01,\n",
       "          -1.0169e-01, -6.6660e-01, -3.4818e-01,  7.0805e-02,  5.0784e-02,\n",
       "          -3.0920e-01,  6.8217e-01,  2.4232e-01,  1.4965e-01, -2.4592e-01,\n",
       "           1.2133e-01, -3.9472e-02,  5.5113e-02,  1.7209e-01, -4.4350e-02,\n",
       "           1.3006e-01, -7.7366e-01, -1.6391e-01,  3.3540e-01, -2.5990e-01,\n",
       "          -5.2553e-01, -4.3163e-01,  3.8076e-01, -3.7089e-01, -5.8388e-01,\n",
       "          -6.9407e-01,  2.3916e-01,  6.2637e-01, -6.9461e-01, -1.7153e-01,\n",
       "           5.1408e-02,  6.0391e-01, -5.4162e-01,  9.2481e-01, -1.8225e-01,\n",
       "           4.5698e-01,  3.9994e-01,  1.1097e-01,  1.6020e-01, -1.4957e-02,\n",
       "           4.5365e-01, -5.9277e-01, -6.4204e-02, -8.3697e-02, -1.5227e-01,\n",
       "          -1.0731e-01,  7.0101e-01, -2.8317e-01,  5.4215e-01,  2.8123e-01,\n",
       "           4.7306e-01, -5.6553e-02, -3.0118e-01,  7.2580e-01, -2.1469e-01,\n",
       "           5.7810e-01, -1.5895e-01, -1.5783e-01,  6.8500e-01,  1.8463e-01,\n",
       "           2.0892e-01,  6.3530e-02, -3.2816e-01, -9.4963e-01,  2.4261e-01,\n",
       "          -9.7529e-01, -8.3901e-01, -1.0577e+00,  1.3939e-01,  7.1645e-02,\n",
       "           3.1157e-01, -7.7615e-02,  3.7419e-01, -1.7860e-01,  3.0424e-01,\n",
       "           1.1692e-01, -8.2598e-01,  3.3932e-02,  6.5057e-02, -5.5734e-02,\n",
       "          -4.4470e-01, -6.4545e-01,  5.2375e-01,  1.2079e-01, -6.2868e-01,\n",
       "          -1.3454e-01, -2.8502e-01,  8.5930e-01, -7.8743e-01, -4.6536e-02,\n",
       "           2.3153e-01,  1.3730e-01, -1.2531e-01,  1.5817e-01,  3.6575e-01,\n",
       "          -1.0469e-01, -5.2552e-01,  4.7030e-01, -4.7990e-01,  2.2983e-01,\n",
       "           5.7225e-01, -9.0771e-01, -6.3794e-01, -5.7866e-02, -7.8832e-01,\n",
       "           2.8386e-01,  2.6150e-01, -3.1875e-01, -2.9547e-01, -3.3221e-01,\n",
       "          -2.2412e-01, -7.4166e-01, -3.1999e-01,  1.1773e-02,  1.6972e-01,\n",
       "           2.9704e-01,  1.3390e-01,  2.4902e-01, -4.7559e-01, -1.4744e-01,\n",
       "           4.2396e-01, -1.0983e-01,  5.3663e-01,  4.0099e-01, -2.3447e-01,\n",
       "           5.7627e-02, -8.7780e-02,  5.9496e-01, -6.1900e-02, -3.9753e-01,\n",
       "           6.6414e-01,  1.4853e-01,  3.6049e-01, -6.5448e-01, -2.7924e-01,\n",
       "           1.8999e-01, -6.5665e-01,  7.7555e-01, -1.4092e-01,  1.5730e-01,\n",
       "           3.3815e-01, -5.8977e-01,  2.2215e-01, -7.0343e-01, -6.7657e-02,\n",
       "          -4.6942e-01,  1.2552e-01,  4.2437e-01,  1.7599e-01, -5.7361e-03,\n",
       "          -2.8409e-01,  5.9804e-01, -7.6429e-01,  5.7815e-01, -1.9435e-01,\n",
       "          -1.7221e-01,  1.1180e+00, -3.5625e-01,  1.8228e-01,  7.6160e-02,\n",
       "           3.7131e-01, -1.6747e-01, -2.2116e-01,  1.9153e-01,  2.0568e-01,\n",
       "           3.3561e-02, -9.7605e-01,  2.6776e-01, -4.6286e-02,  2.5474e-01,\n",
       "           1.5622e-01,  1.1252e+00,  1.7044e-01, -7.5242e-01, -8.0262e-01,\n",
       "           9.9821e-02,  1.3354e+00, -2.0882e-01,  2.3010e-01,  7.6637e-01,\n",
       "           2.3826e-01, -2.0697e-01,  4.1051e-01, -3.6082e-01, -1.0866e-01,\n",
       "           4.1623e-02, -1.0087e-01,  1.7221e-01,  5.2889e-02,  2.4185e-01,\n",
       "           6.4384e-02,  8.3804e-02,  9.7262e-02, -8.6557e-01, -8.5125e-01,\n",
       "          -6.7944e-01, -8.4540e-01,  2.8231e-01,  2.6526e-01,  3.6364e-02,\n",
       "           3.5165e-01, -3.4686e-01,  2.5585e-01,  6.1884e-01, -7.0137e-02,\n",
       "           1.9834e-01,  2.9004e-01, -1.2625e-01,  9.1444e-02,  1.6887e-01,\n",
       "           2.5502e-01,  1.2169e-01,  4.1333e-01, -7.7291e-01, -2.6211e-01,\n",
       "           9.4798e-02, -7.0980e-02,  5.0782e-01,  8.6818e-02, -5.9911e-04,\n",
       "          -2.3330e-01,  7.2644e-01, -3.2736e-01, -4.3597e-01,  5.3894e-01,\n",
       "          -4.3088e-01,  2.7187e-01,  3.8241e-01, -5.5055e-01, -4.8797e-02,\n",
       "           2.0944e-01,  3.5358e-01,  1.8294e-01, -4.7890e-01,  2.7311e-01,\n",
       "           3.0542e-01,  5.3735e-01,  3.9297e-01,  3.0984e-01, -1.7927e-01,\n",
       "          -1.2044e-01, -5.1806e-01, -1.5934e-01, -5.9089e-01,  2.8685e-01,\n",
       "           6.4962e-01, -2.1600e-01,  2.4871e-01, -1.6853e-01, -5.0223e-01,\n",
       "           5.0674e-02,  2.5256e-01, -4.0158e-01, -5.0792e-01,  4.1569e-02,\n",
       "          -4.7228e-02, -6.0984e-01,  3.8424e-01,  3.9956e-01,  4.0958e-01,\n",
       "           5.4930e-03,  5.6964e-01, -7.5203e-02, -1.1329e-01, -1.5475e-01,\n",
       "           3.3257e-01, -5.1201e-01,  2.8140e-01,  5.3009e-01,  1.0881e+00,\n",
       "           6.7032e-01, -2.7891e-02, -2.7781e-01,  6.9075e-01,  5.0148e-01,\n",
       "           6.5740e-01, -2.2085e-01,  1.1848e+00, -7.7722e-01, -1.6918e-01,\n",
       "           3.8170e-01,  3.3837e-01, -7.2388e-02,  2.3218e-02, -7.8790e-01,\n",
       "          -4.7414e-01, -2.9030e-01,  1.7116e-01,  1.6118e-02, -1.5528e-01,\n",
       "           5.6055e-02, -1.5657e-01,  1.2858e-01,  7.7390e-01, -7.2917e-01,\n",
       "          -1.8806e-01,  2.1322e-01, -5.8872e-01, -2.3164e-01, -1.6749e-01,\n",
       "           1.8374e-01, -3.4895e-01, -3.3029e-01, -1.4385e-01,  9.4938e-02,\n",
       "           6.3021e-01, -1.0315e+00, -2.3060e-01,  3.7639e-01, -4.2210e-01,\n",
       "          -2.2254e-01,  1.7170e-01, -2.6564e-01,  3.2275e-02, -6.2562e-01,\n",
       "           1.4116e-01,  4.9226e-02, -2.2585e-01, -1.9995e-01,  2.8363e-01,\n",
       "           6.9550e-01,  1.3064e-01, -4.2438e-01, -9.8160e-01, -9.3058e-02,\n",
       "           3.1312e-01, -1.3909e-01,  3.5144e-01, -2.7406e-01, -6.4134e-01,\n",
       "           1.7397e-01, -3.0431e-01,  4.3781e-01, -3.5184e-02, -6.4187e-01,\n",
       "          -3.9034e-01, -4.0182e-01,  1.8167e-01,  3.7734e-01, -9.9758e-01,\n",
       "           4.6916e-01,  4.7010e-01, -1.1306e-01, -1.6917e-01,  2.7250e-01,\n",
       "           2.7290e-02,  6.4769e-01, -1.8860e-02,  5.0783e-01, -1.2858e-01,\n",
       "          -3.8305e-01,  4.1578e-01, -6.6231e-01, -3.9300e-01, -2.6786e-01,\n",
       "           3.5740e-01, -1.1885e+00, -3.8238e-01, -3.0401e-01, -1.3282e-01,\n",
       "          -3.0195e-02, -2.7682e-01,  1.3576e-01, -4.1803e-01, -8.1384e-02,\n",
       "           5.7549e-01, -6.7204e-01,  5.8632e-01,  1.2154e-01, -1.3084e-01,\n",
       "          -3.9583e-01,  3.5843e-01,  5.2476e-01, -4.2912e-01,  3.6842e-01,\n",
       "          -2.7083e-01, -5.0738e-02, -1.1206e-02,  3.9536e-01, -2.9261e-01,\n",
       "          -5.5381e-03, -1.5517e-01, -2.5480e-01,  1.5107e-01,  1.2184e-01,\n",
       "          -7.5495e-01,  6.8219e-02,  5.0305e-01, -3.5636e-01,  3.1531e-01,\n",
       "          -1.6763e-01, -2.3659e-01,  2.5285e-01,  5.9551e-02,  2.9018e-01,\n",
       "           4.2083e-01, -3.1647e-01,  8.9325e-01,  4.7838e-01,  2.4916e-01,\n",
       "          -2.7042e-02, -1.9676e-01,  2.7202e-01, -6.9658e-02, -2.3437e-02,\n",
       "          -5.2616e-01, -5.4265e-02,  8.2265e-02, -6.1922e-02,  8.5147e-01,\n",
       "           1.2880e-01, -9.8088e-01,  1.4767e-01, -3.9112e-02, -1.6426e-01,\n",
       "           1.2703e-01,  1.6301e-01, -1.0605e-01,  3.0659e-01,  7.2131e-01,\n",
       "           1.7283e-01,  4.5972e-01,  1.2944e-01,  8.0455e-01,  1.9233e-01,\n",
       "           1.0546e-01, -3.1382e-01, -1.0291e+00, -5.4559e-01,  6.3363e-01,\n",
       "          -3.3254e-02,  3.9306e-01,  2.9036e-01,  2.7424e-01,  2.7740e-02,\n",
       "          -2.8373e-01, -5.3053e-01,  3.4222e-01, -8.6390e-02, -7.5082e-01,\n",
       "           1.4635e-01,  2.0858e-02, -4.6409e-01,  1.3909e-01,  1.5723e-01,\n",
       "           1.5426e-01]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.0334, -0.2389, -0.2324,  0.0448, -0.9867,  0.1865,  0.1319]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test prediction\n",
    "muzeronet.prediction(encoded_state=encoded_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0334, -0.2389, -0.2324,  0.0448, -0.9867,  0.1865,  0.1319]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test network units\n",
    "muzeronet.recurrent_inference(encoded_state, action)\n",
    "muzeronet.initial_inference(image).policy_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muzeronet.from_support_to_scalar(muzeronet.initial_inference(image).reward, muzeronet.prediction_support_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing MinMax\n",
    "\n",
    "minmax = MinMaxStats((1,3)) # minmax = MinMaxStats()\n",
    "minmax.normalize(10)\n",
    "# minmax.update(1)\n",
    "# minmax.update(3)\n",
    "minmax.normalize(190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing Muzero config\n",
    "from envs import ConnectNEnv\n",
    "\n",
    "muzeroconfig = MuZeroConfig(ConnectNEnv, {})\n",
    "muzeroconfig.new_game()\n",
    "muzeroconfig.temperature_value(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing atomic functions\n",
    "node = Node(0)\n",
    "node1 = Node(0)\n",
    "node1.visit_count = 10\n",
    "node2 = Node(0.1)\n",
    "node2.visit_count = 20\n",
    "node.children = {1: node1, 2: node2}\n",
    "select_action(muzeroconfig, 20, node, muzeronet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marchitecture\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MuZeroConnectN\n\u001b[1;32m      3\u001b[0m muzeronet \u001b[38;5;241m=\u001b[39m MuZeroConnectN()\n\u001b[0;32m----> 4\u001b[0m play_game(muzeroconfig, muzeronet)\n",
      "File \u001b[0;32m~/Programming/muzero_torch/architecture/engine.py:91\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(config, network)\u001b[0m\n\u001b[1;32m     87\u001b[0m add_exploration_noise(config, root)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# We then run a Monte Carlo Tree Search using only action sequences and the\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# model learned by the network.\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m run_mcts(config, root, game\u001b[38;5;241m.\u001b[39maction_history, game\u001b[38;5;241m.\u001b[39mto_play(), game\u001b[38;5;241m.\u001b[39maction_space(mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), network)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation finished. Current game history \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(game\u001b[38;5;241m.\u001b[39mlength_of_history()))\n\u001b[1;32m     94\u001b[0m game\u001b[38;5;241m.\u001b[39mpresent_game()\n",
      "File \u001b[0;32m~/Programming/muzero_torch/architecture/engine.py:137\u001b[0m, in \u001b[0;36mrun_mcts\u001b[0;34m(config, root, action_history_global, player, full_action_mask, network)\u001b[0m\n\u001b[1;32m    135\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m visited_childs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mhidden_state\n\u001b[1;32m    136\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([action_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m network_output \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mfrom_output_to_scalar(network\u001b[38;5;241m.\u001b[39mrecurrent_inference(last_hidden_state, action), softmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    138\u001b[0m expand_node(node, player, torch\u001b[38;5;241m.\u001b[39mTensor(full_action_mask), network_output)\n\u001b[1;32m    139\u001b[0m visited_childs\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "File \u001b[0;32m~/Programming/muzero_torch/architecture/network.py:147\u001b[0m, in \u001b[0;36mMuZeroNetwork.recurrent_inference\u001b[0;34m(self, hidden_state, action)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecurrent_inference\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state: torch\u001b[38;5;241m.\u001b[39mTensor, action: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NetworkOutput:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;66;03m# dynamics + prediction function\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     next_state, logits_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamics(hidden_state, action)\n\u001b[1;32m    148\u001b[0m     logits_value, logits_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction(next_state)\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NetworkOutput(logits_value, logits_reward, logits_policy, next_state)\n",
      "File \u001b[0;32m~/Programming/muzero_torch/architecture/network.py:117\u001b[0m, in \u001b[0;36mMuZeroNetwork.dynamics\u001b[0;34m(self, encoded_state, action)\u001b[0m\n\u001b[1;32m    114\u001b[0m encoded_action \u001b[38;5;241m=\u001b[39m encoded_action\u001b[38;5;241m.\u001b[39mto(action\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    115\u001b[0m encoded_full_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((encoded_state, encoded_action), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 117\u001b[0m state_representation, logits_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamics_network(encoded_full_state)\n\u001b[1;32m    118\u001b[0m orig_shape \u001b[38;5;241m=\u001b[39m state_representation\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# Scale image along each channel\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/muzero_torch/networks/architecture.py:15\u001b[0m, in \u001b[0;36mDynamicsNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 15\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_net(x)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreward_predictor(next_state)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/muzero_torch/networks/common.py:47\u001b[0m, in \u001b[0;36mGenericResidualNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer(x)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresiduals:\n\u001b[0;32m---> 47\u001b[0m     x \u001b[38;5;241m=\u001b[39m res_layer(x)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Programming/muzero_torch/networks/common.py:28\u001b[0m, in \u001b[0;36mResidualBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m skip_conn \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     27\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvo1(x)\n\u001b[0;32m---> 28\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvo2(x))\n\u001b[1;32m     29\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m skip_conn\n\u001b[1;32m     30\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/aienv/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from architecture.network import MuZeroConnectN\n",
    "\n",
    "muzeronet = MuZeroConnectN()\n",
    "play_game(muzeroconfig, muzeronet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.replay import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "\n",
    "class MuZero:\n",
    "\n",
    "    def __init__(self, config: MuZeroConfig):\n",
    "        self.steps = 0\n",
    "        self.config = config\n",
    "        self.network = self.load_network()\n",
    "\n",
    "    def execute(self):\n",
    "        replay_buffer = ReplayBuffer(self.config.max_buffer_size, self.config.batch_size)\n",
    "\n",
    "        while True:\n",
    "            self.self_play()\n",
    "            self.train_model()\n",
    "\n",
    "    def self_play(self):\n",
    "        pass\n",
    "\n",
    "    def train_model(self, replay_buffer: ReplayBuffer):\n",
    "        network = self.get_latest_network()\n",
    "        optimizer = torch.optim.SGD(network.parameters(), lr=self.config.lr, momentum=self.config.momentum)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=self.config.decaying_func())\n",
    "\n",
    "        for i in self.config.training_steps:\n",
    "            if i%self.config.step_for_saving == 0:\n",
    "                self.save_network()\n",
    "            batch = replay_buffer.sample_batch(self.config.unroll_steps, self.config.td_steps)\n",
    "            self.update_weights(batch, optimizer, network, scheduler)\n",
    "\n",
    "    def update_weights(self, batch: List[Tuple[Tensor, List, List]], optimizer: torch.optim.Optimizer, network: MuZeroNetwork, scheduler: torch.optim.lr_scheduler.LRScheduler = None):\n",
    "\n",
    "        loss = 0\n",
    "        for image, actions, targets in batch:\n",
    "            value, reward, policy_logits, hidden_state = network.initial_inference(image).unpack()\n",
    "            # Grab all predictions as a tuple of: \n",
    "            # - gradient_scale (based on the number of actions)\n",
    "            # - predicted value\n",
    "            # - predicted logits\n",
    "            # - predicted reward\n",
    "            predictions: List[Tuple[float, Tensor, Tensor, Tensor]] = [(1.0, value, policy_logits, reward)]\n",
    "\n",
    "            for action in actions:\n",
    "                value, reward, policy_logits, hidden_state = network.recurrent_inference(hidden_state=hidden_state, action=action).unpack()\n",
    "\n",
    "                # Scale the gradient\n",
    "                predictions.append((1.0/len(actions), value, policy_logits, reward))\n",
    "                # Adjust hidden_state gradient\n",
    "                hidden_state = ut.scale_torch_gradient(hidden_state, self.config.gradient_scale_factor)\n",
    "\n",
    "            for pred, target in zip(predictions, targets):\n",
    "\n",
    "                l = self.calculate_loss(pred, target)\n",
    "\n",
    "    def calculate_loss(self, pred: List[Tuple[float, Tensor, Tensor, Tensor]], target):\n",
    "        scaling_factor, value, policy_logits, reward = pred\n",
    "        target_value, target_reward, target_policy = target\n",
    "\n",
    "\n",
    "    def get_latest_network(self):\n",
    "        network = MuZeroConnectN()\n",
    "        self.load_network(network)\n",
    "        return network\n",
    "        \n",
    "    def load_network(self, network: MuZeroNetwork):\n",
    "        loaded_nets = network.load_network()\n",
    "\n",
    "    def save_network(self, network: MuZeroNetwork):\n",
    "        network.save_network()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def train_network_on_batch(self, network_optim: torch.optim.Optimizer, muzero_network: MuZeroNetwork):\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
