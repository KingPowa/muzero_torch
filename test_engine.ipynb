{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym as g\n",
    "from gym import spaces\n",
    "from connect4 import *\n",
    "from envs import ConnectNEnv\n",
    "from networks.architecture import RepresentationNetwork, DynamicsNetwork, PredictionNetwork\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ConnectNEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'observations': array([[0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0]], dtype=int8),\n",
       "  'action_mask': array([1, 1, 1, 1, 1, 1, 1], dtype=int8),\n",
       "  'player_1_board': array([[0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 0, 0, 0, 0, 0, 0]], dtype=int8),\n",
       "  'player_2_board': array([[0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]], dtype=int8),\n",
       "  'current_player': 'P2'},\n",
       " 0.0,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {'b': 1, 'c': 2}\n",
    "def foo(b,c):\n",
    "    return b+c\n",
    "\n",
    "foo(**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Tuple\n",
    "import utils as ut\n",
    "\n",
    "SUPPORT_SIZE_DEFAULT = 601\n",
    "ENCODED_CHANNELS = 256\n",
    "\n",
    "class NetworkOutput(typing.NamedTuple):\n",
    "    value: torch.Tensor\n",
    "    reward: torch.Tensor\n",
    "    policy_logits: torch.Tensor\n",
    "    hidden_state: torch.Tensor\n",
    "\n",
    "class MuZeroNetwork:\n",
    "\n",
    "    def __init__(self, num_of_features, board_total_slots, n_possible_actions, configs=None):\n",
    "\n",
    "        # Setup configs\n",
    "        configs = self.default_configs(configs)\n",
    "\n",
    "\n",
    "        self.representation_network = RepresentationNetwork(in_channels=num_of_features,\n",
    "                                                            **configs['representation'])\n",
    "\n",
    "        self.prediction_network = PredictionNetwork(in_channels=configs['representation']['n_channels'], \n",
    "                                                    board_total_slots=board_total_slots,\n",
    "                                                    action_space_size=n_possible_actions,\n",
    "                                                    **configs['prediction'])\n",
    "        \n",
    "        self.dynamics_network = DynamicsNetwork(in_channels=configs['representation']['n_channels']+1,\n",
    "                                                  board_total_slots=board_total_slots,\n",
    "                                                  **configs['dynamics'])\n",
    "        \n",
    "        self.prediction_support_size = configs['prediction']['support_size']\n",
    "        self.dynamics_support_size = configs['dynamics']['support_size']\n",
    "        self.action_space_size = n_possible_actions\n",
    "\n",
    "    def default_configs(self, configs):\n",
    "        if configs is None:\n",
    "            configs = {\"prediction\": {}, \"representation\": {}, \"dynamics\": {}}\n",
    "        # Prediction Network\n",
    "        prediction = {\n",
    "            \"n_convs\": 2,\n",
    "            \"n_channels\": ENCODED_CHANNELS,\n",
    "            \"n_residual_layers\": 10,\n",
    "            \"kernel_size\": (3,3),\n",
    "            \"support_size\": SUPPORT_SIZE_DEFAULT\n",
    "        }\n",
    "        if \"prediction\" not in configs: \n",
    "            configs[\"prediction\"] = prediction\n",
    "        else:\n",
    "            ut.fill_defaults(configs[\"prediction\"], prediction)\n",
    "            # Check if Support Size is ok\n",
    "            if not (configs[\"prediction\"]['support_size']-1) % 2 == 0: \n",
    "                print(\"[NETWORK - Prediction] Support Size invalid. Set to default = {}.\".format(SUPPORT_SIZE_DEFAULT))\n",
    "                configs[\"prediction\"]['support_size'] = SUPPORT_SIZE_DEFAULT\n",
    "        # Representation Network\n",
    "        representation = {\n",
    "            \"n_channels\": ENCODED_CHANNELS,\n",
    "            \"n_residual_layers\": 10,\n",
    "            \"kernel_size\": (3,3)\n",
    "        }\n",
    "        if \"representation\" not in configs: \n",
    "            configs[\"representation\"] = representation\n",
    "        else:\n",
    "            ut.fill_defaults(configs[\"representation\"], representation)\n",
    "        # Dynamics Network\n",
    "        dynamics = {\n",
    "            \"n_convs\": 2,\n",
    "            \"n_channels\": ENCODED_CHANNELS,\n",
    "            \"n_residual_layers\": 10,\n",
    "            \"kernel_size\": (3,3),\n",
    "            \"support_size\": SUPPORT_SIZE_DEFAULT\n",
    "        }\n",
    "        if \"dynamics\" not in configs: \n",
    "            configs[\"dynamics\"] = dynamics\n",
    "        else:\n",
    "            ut.fill_defaults(configs[\"dynamics\"], dynamics)\n",
    "            # Check if Support Size is ok\n",
    "            if not (configs[\"dynamics\"]['support_size']-1) % 2 == 0: \n",
    "                print(\"[NETWORK - Dynamics] Support Size invalid. Set to default = {}.\".format(SUPPORT_SIZE_DEFAULT))\n",
    "                configs[\"dynamics\"]['support_size'] = SUPPORT_SIZE_DEFAULT\n",
    "\n",
    "        return configs\n",
    "\n",
    "    def representation(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        state_representation = self.representation_network(image)\n",
    "        orig_shape = state_representation.shape\n",
    "        # Scale image along each channel\n",
    "        max_per_channel = state_representation.view(\n",
    "            orig_shape[0],\n",
    "            orig_shape[1],\n",
    "            -1\n",
    "        ).max(2, keepdim=True)[0].unsqueeze(-1)\n",
    "        min_per_channel = state_representation.view(\n",
    "            orig_shape[0],\n",
    "            orig_shape[1],\n",
    "            -1\n",
    "        ).min(2, keepdim=True)[0].unsqueeze(-1)\n",
    "        scale = max_per_channel - min_per_channel\n",
    "        scale[scale <= 0] += 1e-5\n",
    "        return (state_representation - min_per_channel) / scale\n",
    "    \n",
    "    def prediction(self, encoded_state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Predict via state the policy logits and value function\n",
    "        return self.prediction_network(encoded_state)\n",
    "    \n",
    "    def dynamics(self, encoded_state: torch.Tensor, action: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Encode the action\n",
    "        enc_state_shape = encoded_state.shape\n",
    "        encoded_action = torch.zeros((enc_state_shape[0], 1, enc_state_shape[2], enc_state_shape[3])) / (self.action_space_size-action)\n",
    "        encoded_action = encoded_action * action[:,:,None,None] / self.action_space_size\n",
    "        encoded_action = encoded_action.to(action.device)\n",
    "        encoded_full_state = torch.cat((encoded_state, encoded_action), dim=1)\n",
    "\n",
    "        print(encoded_full_state.shape)\n",
    "\n",
    "        state_representation, logits_reward = self.dynamics_network(encoded_full_state)\n",
    "        orig_shape = state_representation.shape\n",
    "        # Scale image along each channel\n",
    "        max_per_channel = state_representation.view(\n",
    "            orig_shape[0],\n",
    "            orig_shape[1],\n",
    "            -1\n",
    "        ).max(2, keepdim=True)[0].unsqueeze(-1)\n",
    "        min_per_channel = state_representation.view(\n",
    "            orig_shape[0],\n",
    "            orig_shape[1],\n",
    "            -1\n",
    "        ).min(2, keepdim=True)[0].unsqueeze(-1)\n",
    "        scale = max_per_channel - min_per_channel\n",
    "        scale[scale <= 0] += 1e-5\n",
    "\n",
    "        return (state_representation - min_per_channel) / scale, logits_reward\n",
    "  \n",
    "    def initial_inference(self, image: torch.Tensor) -> NetworkOutput:\n",
    "        # representation + prediction function\n",
    "        state_representation = self.representation(image)\n",
    "        logits_value, logits_policy = self.prediction(state_representation)\n",
    "\n",
    "        logits_reward = torch.ones(image.shape[0], self.prediction_support_size) * -float(\"inf\")\n",
    "        logits_reward[:, self.prediction_support_size//2] = 0.0\n",
    "\n",
    "        return NetworkOutput(logits_value, logits_reward, logits_policy, state_representation)\n",
    "\n",
    "    def recurrent_inference(self, hidden_state: torch.Tensor, action: torch.Tensor) -> NetworkOutput:\n",
    "        # dynamics + prediction function\n",
    "        next_state, logits_reward = self.dynamics(hidden_state, action)\n",
    "        logits_value, logits_policy = self.prediction(next_state)\n",
    "\n",
    "        return NetworkOutput(logits_value, logits_reward, logits_policy, next_state)\n",
    "\n",
    "    def get_weights(self):\n",
    "        # Returns the weights of this network.\n",
    "        return []\n",
    "\n",
    "    def training_steps(self) -> int:\n",
    "        # How many steps / batches the network has been trained for.\n",
    "        return 0\n",
    "    \n",
    "    def from_output_to_scalar(self, network_output: NetworkOutput, softmax=False, type_output=\"prediction\"):\n",
    "        network_output.value = self.from_support_to_scalar(network_output.value, \n",
    "                                                      self.prediction_support_size if type_output == \"prediction\" else self.dynamics_support_size)\n",
    "        network_output.reward = self.from_support_to_scalar(network_output.reward, \n",
    "                                                      self.prediction_support_size if type_output == \"prediction\" else self.dynamics_support_size)\n",
    "        if softmax: network_output.policy_logits = torch.nn.functional.softmax(network_output.policy_logits, dim=1)\n",
    "        return network_output\n",
    "    \n",
    "    def from_support_to_scalar(self, weights: torch.Tensor, support_size: int) -> torch.Tensor:\n",
    "        # Get value for each support\n",
    "        support_vector = torch.arange(-(support_size-1)//2, (support_size-1)//2+1).expand(weights.shape).float().to(weights.device)\n",
    "        w_softmax = torch.nn.functional.softmax(weights, dim=-1)\n",
    "        result = torch.sum(support_vector*w_softmax, dim=1, keepdim=True) # Keep dims make it N x D -> N x 1\n",
    "        # Result is trained with a scaling function h(x), apply it inversely\n",
    "        return inverse_h(result)\n",
    "\n",
    "\n",
    "def h(x: torch.Tensor, eps = 1e-2) -> torch.Tensor:\n",
    "    elem = torch.sqrt(torch.sign(x)+1) - 1\n",
    "    return torch.sign(x) * elem + eps * x\n",
    "\n",
    "def inverse_h(x: torch.Tensor, eps = 1e-2) -> torch.Tensor:\n",
    "    elem = torch.abs(x) + 1 + eps\n",
    "    elem = torch.sqrt(1 + 4 * eps * elem) - 1\n",
    "    elem = ((elem / 2 * eps) ** 2) - 1\n",
    "    return torch.sign(x) * elem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](images/inverseh.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "muzeronet = MuZeroNetwork(3, 42, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.0386, 0.2679, 0.6434, 0.3073, 0.8630, 0.3129, 0.4499],\n",
      "          [0.4925, 0.2986, 0.3502, 0.7347, 0.1663, 0.4028, 0.7979],\n",
      "          [0.6699, 0.4449, 0.0810, 0.9388, 0.5247, 0.7416, 0.2737],\n",
      "          [0.1082, 0.8635, 0.9558, 0.2710, 0.5138, 0.7743, 0.6261],\n",
      "          [0.2529, 0.4488, 0.0707, 0.1945, 0.8124, 0.0782, 0.0609],\n",
      "          [0.4100, 0.6586, 0.2137, 0.4823, 0.1103, 0.5244, 0.7674]],\n",
      "\n",
      "         [[0.2759, 0.8199, 0.7194, 0.1569, 0.5720, 0.8551, 0.8672],\n",
      "          [0.0933, 0.3919, 0.8842, 0.7446, 0.6284, 0.6497, 0.1409],\n",
      "          [0.9564, 0.7636, 0.0699, 0.7818, 0.6452, 0.6021, 0.8207],\n",
      "          [0.6475, 0.8894, 0.8558, 0.5189, 0.8223, 0.4391, 0.8745],\n",
      "          [0.2931, 0.5125, 0.9808, 0.2686, 0.1246, 0.3248, 0.5832],\n",
      "          [0.8053, 0.3317, 0.6834, 0.5776, 0.2721, 0.7754, 0.6393]],\n",
      "\n",
      "         [[0.3497, 0.2233, 0.3920, 0.1998, 0.8273, 0.5209, 0.9985],\n",
      "          [0.2892, 0.8194, 0.2255, 0.3047, 0.6062, 0.0439, 0.5854],\n",
      "          [0.4943, 0.4999, 0.2096, 0.6426, 0.2777, 0.0010, 0.6712],\n",
      "          [0.5315, 0.9040, 0.6458, 0.1604, 0.2439, 0.5122, 0.4820],\n",
      "          [0.6057, 0.3783, 0.4684, 0.5401, 0.3267, 0.0596, 0.8413],\n",
      "          [0.2148, 0.2075, 0.3454, 0.4245, 0.0282, 0.1466, 0.1691]]]])\n"
     ]
    }
   ],
   "source": [
    "# Test representation\n",
    "image = torch.rand((1,3,6,7))\n",
    "print(image)\n",
    "encoded_state = muzeronet.representation(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.]]) torch.Size([1, 1])\n",
      "torch.Size([1, 257, 6, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[2.1336e-01, 2.1317e-01, 5.1032e-01,  ..., 9.9445e-03,\n",
       "            1.3274e-02, 1.2339e-01],\n",
       "           [4.6829e-02, 3.4161e-03, 7.2424e-02,  ..., 0.0000e+00,\n",
       "            5.9160e-02, 3.3592e-01],\n",
       "           [1.7596e-01, 3.4086e-02, 2.7011e-01,  ..., 0.0000e+00,\n",
       "            1.0000e+00, 0.0000e+00],\n",
       "           [1.2625e-01, 1.7195e-01, 7.9518e-01,  ..., 0.0000e+00,\n",
       "            4.0509e-01, 0.0000e+00],\n",
       "           [1.1800e-01, 4.5758e-02, 2.5525e-01,  ..., 5.0373e-01,\n",
       "            2.6358e-01, 4.4332e-01],\n",
       "           [4.0323e-01, 4.6812e-01, 2.1140e-01,  ..., 1.8294e-01,\n",
       "            1.6341e-01, 2.4817e-02]],\n",
       " \n",
       "          [[3.1781e-02, 2.5497e-01, 5.8762e-01,  ..., 0.0000e+00,\n",
       "            2.3663e-01, 1.6260e-01],\n",
       "           [4.3784e-01, 3.8282e-01, 8.6672e-02,  ..., 8.5371e-01,\n",
       "            1.0000e+00, 2.6081e-01],\n",
       "           [1.5693e-01, 1.5369e-01, 5.8974e-01,  ..., 5.9598e-01,\n",
       "            2.7737e-01, 4.7345e-01],\n",
       "           [5.8503e-01, 1.5988e-01, 3.1179e-01,  ..., 1.0412e-01,\n",
       "            4.5351e-01, 6.1388e-01],\n",
       "           [0.0000e+00, 3.4099e-01, 7.2299e-02,  ..., 0.0000e+00,\n",
       "            3.4284e-01, 7.7571e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 3.0455e-01,  ..., 2.8554e-02,\n",
       "            6.6678e-01, 0.0000e+00]],\n",
       " \n",
       "          [[5.7273e-02, 5.6690e-02, 3.4915e-01,  ..., 3.1623e-01,\n",
       "            0.0000e+00, 2.3661e-01],\n",
       "           [1.7862e-01, 3.1718e-01, 1.3134e-01,  ..., 7.4538e-02,\n",
       "            0.0000e+00, 2.4831e-01],\n",
       "           [0.0000e+00, 3.8970e-01, 1.6401e-02,  ..., 3.0688e-01,\n",
       "            3.7894e-01, 1.2033e-01],\n",
       "           [2.5314e-01, 1.0000e+00, 2.8667e-01,  ..., 2.6921e-01,\n",
       "            0.0000e+00, 0.0000e+00],\n",
       "           [1.2951e-01, 9.7365e-02, 1.2562e-01,  ..., 1.7553e-01,\n",
       "            0.0000e+00, 1.1307e-01],\n",
       "           [7.9048e-01, 3.1408e-01, 8.2439e-01,  ..., 2.3876e-01,\n",
       "            4.9745e-01, 2.8059e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[2.8755e-01, 1.8117e-01, 2.6435e-01,  ..., 9.5555e-02,\n",
       "            0.0000e+00, 4.1567e-01],\n",
       "           [1.1227e-01, 4.2392e-01, 2.0110e-01,  ..., 0.0000e+00,\n",
       "            3.9256e-01, 0.0000e+00],\n",
       "           [6.9429e-04, 1.0000e+00, 0.0000e+00,  ..., 5.8041e-02,\n",
       "            6.7719e-02, 0.0000e+00],\n",
       "           [3.0457e-01, 4.1550e-01, 5.7261e-02,  ..., 5.4882e-01,\n",
       "            1.3057e-01, 0.0000e+00],\n",
       "           [1.8776e-01, 1.0957e-01, 7.6008e-02,  ..., 0.0000e+00,\n",
       "            2.1139e-01, 2.3263e-02],\n",
       "           [2.6697e-01, 3.4012e-01, 0.0000e+00,  ..., 2.8376e-02,\n",
       "            1.2167e-01, 1.1956e-01]],\n",
       " \n",
       "          [[7.2473e-01, 6.6056e-01, 1.4662e-01,  ..., 5.1097e-01,\n",
       "            9.3191e-01, 0.0000e+00],\n",
       "           [9.5726e-01, 0.0000e+00, 0.0000e+00,  ..., 2.7920e-01,\n",
       "            8.0375e-01, 1.5672e-01],\n",
       "           [4.7381e-01, 2.0354e-01, 9.4350e-01,  ..., 6.2010e-01,\n",
       "            0.0000e+00, 5.4335e-01],\n",
       "           [2.3901e-01, 6.2462e-01, 4.8651e-02,  ..., 7.1241e-01,\n",
       "            1.0000e+00, 0.0000e+00],\n",
       "           [2.6926e-01, 2.5583e-01, 2.3107e-01,  ..., 0.0000e+00,\n",
       "            2.6948e-01, 6.7631e-01],\n",
       "           [2.8866e-01, 1.4274e-01, 1.1292e-01,  ..., 3.4805e-01,\n",
       "            0.0000e+00, 0.0000e+00]],\n",
       " \n",
       "          [[1.4936e-01, 2.4025e-01, 1.1985e-01,  ..., 4.1902e-01,\n",
       "            5.1345e-01, 3.8841e-01],\n",
       "           [1.5030e-01, 0.0000e+00, 2.3078e-01,  ..., 0.0000e+00,\n",
       "            5.2996e-01, 4.9393e-01],\n",
       "           [0.0000e+00, 0.0000e+00, 8.9196e-01,  ..., 5.7726e-01,\n",
       "            8.0404e-01, 3.2134e-01],\n",
       "           [0.0000e+00, 8.0006e-01, 3.5037e-01,  ..., 1.1194e-01,\n",
       "            0.0000e+00, 8.8949e-01],\n",
       "           [9.1068e-02, 1.0000e+00, 1.7042e-01,  ..., 3.3917e-01,\n",
       "            7.6008e-01, 5.7408e-01],\n",
       "           [0.0000e+00, 7.9043e-02, 2.5941e-01,  ..., 0.0000e+00,\n",
       "            0.0000e+00, 1.1195e-01]]]], grad_fn=<DivBackward0>),\n",
       " tensor([[-3.8816e-01, -3.7462e-01, -2.0705e-01,  4.4918e-01,  5.1155e-01,\n",
       "           1.2244e-01,  3.8788e-01,  7.8808e-01, -2.6225e-02, -8.4556e-01,\n",
       "          -2.9160e-02, -2.5175e-01,  4.9007e-01, -7.2042e-01, -2.7867e-01,\n",
       "           6.8305e-01, -1.2102e-01,  2.6018e-01,  3.5566e-01, -2.8633e-01,\n",
       "          -6.7145e-01, -6.9760e-01, -1.9319e-01, -4.2424e-01, -9.4872e-02,\n",
       "          -2.9607e-01, -6.8953e-01, -4.8551e-01, -4.5319e-02,  8.6008e-02,\n",
       "           2.0665e-01,  1.3866e-01,  5.1172e-01, -8.7670e-02, -1.0527e-01,\n",
       "          -2.1637e-01, -4.1554e-01,  3.6907e-01,  5.2737e-01, -3.7281e-01,\n",
       "          -3.4795e-01, -1.3891e-01, -4.0971e-01,  6.5842e-01, -4.7172e-01,\n",
       "           5.6254e-01,  1.7770e-02,  1.0278e-03,  5.5676e-02,  9.9372e-02,\n",
       "           4.0522e-01,  2.4638e-01, -7.2965e-02,  4.6081e-02, -2.2202e-01,\n",
       "           1.5343e-01, -1.3454e-01,  1.1883e-02, -3.9003e-01,  3.5256e-02,\n",
       "          -2.1147e-02,  3.9236e-02, -5.0688e-01, -3.2668e-01, -3.8861e-01,\n",
       "           3.9804e-02,  3.3633e-02, -1.5424e-01,  1.4760e-01, -3.8805e-01,\n",
       "           5.3227e-01,  6.8505e-02,  3.7789e-01,  1.3176e-01, -4.5408e-01,\n",
       "           4.4326e-01,  2.4127e-01,  3.4254e-01,  2.6373e-01,  1.1244e-01,\n",
       "           2.2330e-01,  1.8669e-01,  3.7183e-01, -1.4802e-01,  7.0442e-02,\n",
       "           3.8300e-01,  8.5173e-02, -1.9344e-01, -3.1204e-01,  5.4705e-01,\n",
       "           5.7379e-01, -3.1115e-01,  1.6652e-01,  4.1056e-01,  2.0096e-01,\n",
       "           7.7543e-01,  1.2845e-01, -2.2993e-02, -1.0934e-01,  3.2124e-02,\n",
       "          -1.3829e-01,  9.7460e-02, -8.6612e-01, -4.5993e-01, -3.1228e-01,\n",
       "           5.1438e-01,  1.2044e-01, -2.8207e-01,  2.5757e-01, -8.3631e-02,\n",
       "           1.5488e-03, -1.5661e-01,  3.5877e-01,  3.4283e-01, -8.0565e-02,\n",
       "          -6.6416e-01,  1.4778e-01, -2.0728e-01, -6.4306e-01, -4.7755e-02,\n",
       "          -7.9757e-02,  3.9288e-01, -1.5058e-01,  1.8732e-01, -4.6189e-01,\n",
       "           1.4932e-01,  1.6263e-01,  1.3647e-01, -2.4435e-02, -2.2392e-01,\n",
       "           2.7776e-01,  6.5406e-01,  2.6278e-01, -2.5130e-01, -5.0735e-01,\n",
       "           3.1350e-01, -4.2333e-01, -8.4078e-01,  1.7916e-03,  1.4345e-01,\n",
       "          -5.8738e-01, -1.4995e-01,  1.9035e-01, -9.4331e-02,  2.1036e-01,\n",
       "          -1.1607e-01, -1.4818e+00, -6.5331e-01,  2.1637e-01,  2.4208e-01,\n",
       "          -3.5034e-01,  2.1538e-01,  2.4937e-01, -3.3288e-01,  3.7395e-01,\n",
       "           9.4361e-01, -3.7715e-01,  3.8725e-01, -9.9867e-02, -1.9793e-01,\n",
       "           2.3060e-01, -3.8530e-02, -4.3982e-02, -8.7133e-01,  3.5729e-01,\n",
       "          -2.4500e-01,  8.6627e-02,  2.7704e-01, -4.5137e-01,  6.7488e-01,\n",
       "           2.6701e-01,  4.2439e-02,  8.8203e-02,  2.5680e-01, -3.1603e-01,\n",
       "          -6.6625e-01,  6.0645e-01, -8.5783e-02, -3.2969e-01, -4.6807e-01,\n",
       "          -3.1133e-01,  6.7307e-02, -3.8890e-01, -2.0368e-01,  1.7685e-01,\n",
       "          -6.4241e-01,  5.2383e-01,  2.7784e-01, -3.0783e-01, -7.1319e-01,\n",
       "           5.1903e-01, -1.9723e-01,  1.4505e-01, -2.4542e-01, -8.9763e-01,\n",
       "          -2.2308e-01, -3.9412e-01, -2.2386e-01,  4.9826e-01, -5.0388e-01,\n",
       "           3.9804e-01,  2.8248e-01, -3.6946e-01, -5.5605e-02,  9.3272e-02,\n",
       "           1.0584e-01, -8.3449e-01, -7.8974e-02,  4.5062e-01,  4.7219e-01,\n",
       "          -3.9963e-01, -2.4699e-01,  2.8176e-01,  1.9822e-01,  1.2997e-01,\n",
       "           8.6965e-01, -2.4408e-02,  4.9200e-01, -7.7850e-02, -4.4495e-01,\n",
       "           2.4853e-01,  1.1874e-01,  6.5393e-01,  2.6846e-01, -9.3647e-03,\n",
       "           4.2966e-02,  3.5831e-01, -1.7566e-01,  4.8634e-01,  8.2674e-02,\n",
       "          -2.6300e-01,  2.4276e-01, -4.9220e-01, -4.9179e-01, -6.5832e-01,\n",
       "           6.8752e-01,  2.6092e-01,  2.2202e-01, -4.0167e-02,  3.1555e-01,\n",
       "           8.1844e-01,  3.4071e-01,  8.2172e-02, -2.6145e-01, -5.9293e-01,\n",
       "          -1.8039e-01,  2.6452e-01, -6.5418e-02,  4.1766e-02,  9.3176e-01,\n",
       "           1.3458e-01, -5.1832e-01, -6.2415e-01,  4.5972e-01, -4.2242e-01,\n",
       "           1.7951e-01, -3.3155e-01, -1.4220e-01,  3.7862e-01, -1.9761e-01,\n",
       "          -8.0771e-02,  9.6466e-01, -1.8466e-01, -5.6329e-01, -1.7686e-01,\n",
       "           2.1027e-01, -3.2789e-01,  8.0062e-01,  4.3037e-01,  1.0544e+00,\n",
       "          -3.2380e-01,  3.9019e-01, -6.5932e-01, -1.6300e-01,  1.6491e-01,\n",
       "          -4.6837e-01, -4.9297e-01, -3.9970e-01, -9.8246e-01, -7.2906e-01,\n",
       "          -1.2031e-01, -4.8899e-01, -4.9477e-02, -1.9657e-01, -8.3606e-01,\n",
       "           3.4037e-01,  5.5896e-01,  4.0230e-01,  3.7692e-01,  3.0513e-02,\n",
       "          -8.6260e-02, -5.6266e-01,  1.6095e-01,  1.8314e-01,  1.8494e-01,\n",
       "          -2.0421e-01, -7.3892e-01, -1.7622e-01,  8.0202e-02, -1.0460e+00,\n",
       "          -2.4641e-01,  4.8971e-01,  9.3098e-01, -3.7440e-02, -7.8950e-01,\n",
       "          -7.9049e-01,  4.7113e-01, -9.8518e-02, -5.2650e-01, -1.0916e-01,\n",
       "          -1.6757e-02,  2.1292e-01, -3.2754e-01, -1.9031e-01, -2.4754e-01,\n",
       "          -1.9213e-01, -7.3123e-01, -3.8264e-01, -1.4150e-03,  1.8407e-01,\n",
       "           6.4429e-01, -4.0805e-01, -3.4908e-01,  5.1477e-01,  8.0189e-02,\n",
       "           2.1078e-01, -8.3971e-03, -6.6647e-01,  2.8556e-01,  5.3292e-02,\n",
       "          -5.2763e-01,  7.1065e-01, -3.6668e-01,  2.6009e-01,  3.1295e-02,\n",
       "          -9.2683e-01, -5.4208e-02,  5.1494e-01,  2.6514e-01, -5.5310e-01,\n",
       "           4.9174e-01, -1.1466e-01,  7.5629e-01, -3.5696e-01,  1.9804e-02,\n",
       "           3.3983e-01,  5.9027e-01, -3.8539e-01,  4.7790e-01,  4.4086e-01,\n",
       "          -3.2975e-02, -1.1700e-01,  6.0493e-02, -2.5425e-01,  6.1630e-01,\n",
       "          -1.2404e-01, -1.9508e-01,  7.1555e-01,  2.2134e-01,  1.9419e-02,\n",
       "           5.0750e-01,  1.5663e-01,  1.4268e-01, -6.7367e-01,  3.4240e-01,\n",
       "           8.3728e-02, -5.0645e-01, -3.2753e-01, -1.5020e-01, -5.1377e-01,\n",
       "           7.5766e-02,  1.2407e-01,  3.9261e-01, -2.6387e-01, -4.7694e-01,\n",
       "           3.8723e-01,  7.6303e-01,  3.1180e-01,  1.8289e-01, -4.2855e-01,\n",
       "           3.3054e-01, -2.3705e-01,  2.8526e-01, -3.6885e-01,  2.8811e-01,\n",
       "           2.0339e-03,  1.6246e-01,  2.3802e-01,  5.5277e-01,  2.7505e-01,\n",
       "          -3.2630e-01, -7.4492e-01, -1.9183e-01,  1.4737e-01,  1.4495e-01,\n",
       "           4.9949e-01,  7.9379e-02, -5.0827e-01, -4.5416e-01, -1.0893e-01,\n",
       "           3.5707e-01, -1.7524e-01, -5.0838e-01,  5.3871e-01, -3.8758e-01,\n",
       "          -3.7441e-01,  9.3199e-03,  6.5234e-01,  1.4191e-01,  2.9919e-01,\n",
       "          -3.1712e-01,  7.7992e-01,  1.6931e-01,  3.1514e-01, -2.3069e-01,\n",
       "           1.1810e-01, -8.6919e-01, -2.4132e-01,  3.7696e-01, -3.5682e-01,\n",
       "           6.2843e-01, -1.4760e-01,  2.0509e-01, -1.1606e-01,  4.4622e-01,\n",
       "          -1.1828e-01, -2.2329e-01, -6.0265e-01,  1.3319e-01, -1.4325e-01,\n",
       "           1.2794e-01, -3.1537e-01, -4.1365e-01, -7.5273e-02,  1.7408e-01,\n",
       "           6.5683e-01, -9.0425e-01,  4.2130e-01, -6.8001e-02, -2.6726e-02,\n",
       "           7.2570e-01,  1.3664e-01, -3.8564e-02, -3.5469e-01,  1.3089e-01,\n",
       "           4.8971e-01, -5.5581e-01,  8.1332e-01,  4.9269e-01, -4.1551e-01,\n",
       "          -6.4253e-01,  1.2051e-02,  2.9575e-01,  1.6677e-02,  4.6601e-01,\n",
       "          -8.0576e-02,  9.3442e-02, -2.3129e-01, -4.2811e-01, -2.6253e-01,\n",
       "          -6.9051e-01,  3.2722e-01, -3.1130e-01,  5.1282e-02, -7.1183e-01,\n",
       "          -9.3428e-02,  2.4288e-01, -5.3042e-01, -3.3998e-01,  1.2266e+00,\n",
       "           6.9155e-01, -3.1043e-02, -7.5657e-01, -2.8463e-01, -5.7192e-02,\n",
       "           2.5481e-01,  8.5814e-01, -1.7305e-01, -2.4552e-01, -2.2149e-01,\n",
       "           4.6457e-01,  6.6086e-01, -3.6945e-01,  6.8139e-01,  1.3624e-01,\n",
       "          -4.2675e-02,  1.1507e-01, -4.8806e-02, -1.1988e-02, -2.1977e-01,\n",
       "          -8.5457e-02,  3.9127e-01, -2.7573e-01, -5.5420e-01,  1.8828e-01,\n",
       "          -6.8605e-01,  6.9157e-01, -6.8311e-01,  3.6796e-01,  1.8491e-01,\n",
       "           4.1187e-01, -4.6284e-01, -2.6218e-01, -5.2038e-01, -1.7712e-01,\n",
       "          -5.4079e-01, -7.3106e-01,  4.9738e-01, -1.3003e-01, -4.4722e-01,\n",
       "          -2.8551e-01,  5.3584e-01,  3.3432e-02, -9.4545e-02, -4.9124e-01,\n",
       "           5.5573e-01,  7.0837e-02, -4.0933e-01, -2.0944e-01,  4.0209e-02,\n",
       "           2.3655e-03, -9.3138e-01,  4.3733e-01,  2.0403e-01, -2.6479e-01,\n",
       "           8.9511e-02, -2.3843e-01, -5.2210e-01,  1.9936e-01,  1.0289e-01,\n",
       "          -2.3886e-01, -2.7907e-01,  8.7739e-03, -3.6325e-01,  2.4986e-01,\n",
       "          -3.9414e-04,  3.3684e-01,  1.0686e+00, -8.4365e-02, -1.0120e-01,\n",
       "          -2.4003e-03, -2.6488e-01,  1.6877e-02,  3.4502e-01,  3.5735e-01,\n",
       "          -6.0098e-02, -3.0999e-01, -7.6644e-05,  2.7532e-01,  3.5350e-01,\n",
       "          -8.0407e-01,  1.4840e-01,  5.0929e-01, -2.4208e-01, -4.3088e-01,\n",
       "          -6.2730e-02, -2.3793e-01,  4.0630e-01,  2.9092e-01,  1.4956e-01,\n",
       "           3.9646e-01, -2.4583e-01, -1.5734e-01, -6.2790e-02, -1.2656e-01,\n",
       "           2.0030e-02,  3.8022e-01,  7.7630e-01,  5.3520e-02, -3.1994e-01,\n",
       "          -4.4116e-01, -1.7155e-02,  1.3537e-01, -1.9523e-01,  1.0554e+00,\n",
       "          -1.2126e-01, -2.6782e-01, -4.2311e-01, -1.0605e+00, -2.6917e-01,\n",
       "           1.9308e-01,  6.9101e-01,  1.1599e-01, -1.4584e-01, -6.0394e-01,\n",
       "          -2.6620e-01,  1.5606e-01, -3.8360e-01, -4.0412e-01,  9.9943e-01,\n",
       "          -2.5989e-01,  1.0995e-01,  7.7305e-01, -7.3359e-01,  2.5587e-01,\n",
       "           8.0916e-02, -8.9860e-01, -1.5023e-01,  4.4488e-01, -2.1558e-01,\n",
       "          -4.8245e-01]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test dynamics\n",
    "action = torch.Tensor([2]).view(1,1)\n",
    "print(action, action.shape)\n",
    "muzeronet.dynamics(encoded_state=encoded_state, action=action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.5555e-01,  4.7511e-01, -3.8508e-01,  2.3560e-01, -6.3837e-01,\n",
       "          -1.5231e-01, -3.7004e-01,  1.2284e-01, -4.0252e-01, -2.4308e-01,\n",
       "          -3.7495e-01,  9.5926e-01, -4.5886e-02,  6.4188e-02,  4.8787e-01,\n",
       "           2.1640e-02,  1.6183e-01, -7.6442e-01,  5.7617e-01, -3.4079e-01,\n",
       "           2.7731e-01,  6.8389e-01, -9.9300e-01, -4.9711e-01,  2.7927e-01,\n",
       "           3.2501e-02,  2.8765e-01, -6.9023e-01,  8.7574e-01,  4.2982e-01,\n",
       "           6.8780e-02, -5.7019e-01, -6.4011e-01,  1.3984e-01, -3.5868e-01,\n",
       "          -7.6078e-01,  4.3228e-01,  6.1998e-01,  5.2586e-01, -5.5810e-01,\n",
       "          -5.4709e-01,  2.1746e-01, -6.0428e-01, -6.6087e-01,  3.6234e-01,\n",
       "          -8.6921e-01, -2.3995e-02,  1.1392e+00, -1.0026e-01, -2.1926e-01,\n",
       "          -7.4684e-02,  4.3344e-01,  9.8553e-02, -6.4525e-01, -1.4633e-01,\n",
       "           9.5027e-02,  2.7810e-01, -1.0050e-01, -1.3950e-01, -3.2122e-02,\n",
       "          -1.8442e-01, -3.3964e-01,  2.0572e-01,  3.2133e-01, -1.4949e-01,\n",
       "          -4.0256e-01,  9.5514e-04,  4.2832e-01,  6.8582e-02,  8.0375e-02,\n",
       "           4.8631e-01,  8.4893e-02,  1.9853e-01, -2.6047e-01, -1.0323e-01,\n",
       "           7.7387e-01, -7.3876e-01,  5.1879e-01, -2.3469e-02,  2.5145e-01,\n",
       "          -3.0735e-01, -2.9962e-01, -4.7193e-01, -1.6165e-01, -4.2697e-01,\n",
       "           3.5752e-01, -2.7055e-02, -1.6545e-01,  1.1489e-03, -9.4845e-02,\n",
       "          -8.9192e-01, -2.2128e-01, -9.4322e-02, -5.2768e-01, -8.7130e-04,\n",
       "           3.2393e-01,  1.0748e-01, -3.8776e-02,  3.1318e-01, -2.6926e-02,\n",
       "          -1.4139e-01, -6.6758e-01,  4.9656e-02, -4.2671e-01, -1.4453e-01,\n",
       "          -1.8730e-01, -7.4792e-01,  1.2374e+00,  8.0853e-01, -9.4417e-02,\n",
       "          -2.4179e-01, -6.0747e-01,  7.2086e-01, -2.6755e-01, -1.1036e-02,\n",
       "           3.1490e-02,  6.6308e-02,  3.1775e-01,  1.8190e-02, -7.5396e-02,\n",
       "          -2.6698e-01, -8.7741e-02, -2.7457e-01, -1.6079e-01,  7.7646e-01,\n",
       "          -6.1835e-01, -6.7157e-02, -1.0252e-01,  3.4155e-02, -7.9147e-01,\n",
       "           7.0216e-03, -1.1295e-01,  8.2593e-01, -4.9424e-01, -2.1845e-01,\n",
       "          -3.3562e-01,  1.9135e-01,  2.4774e-01,  3.7824e-01,  9.0609e-02,\n",
       "           5.5159e-01,  2.6450e-01, -2.2138e-01,  2.6503e-01,  2.0079e-01,\n",
       "           5.4676e-01, -3.0408e-01, -3.3029e-01,  4.4903e-01, -7.0583e-01,\n",
       "          -3.8526e-01,  5.9252e-01,  2.0361e-01, -2.0478e-01,  9.8657e-01,\n",
       "           2.8300e-01,  9.5278e-01, -3.6987e-01,  3.4014e-01, -1.6757e-02,\n",
       "          -5.0471e-02,  4.0788e-01,  5.7807e-01,  3.0878e-01,  5.7761e-01,\n",
       "          -4.6050e-01, -1.5120e-01,  2.4704e-01, -8.0099e-01,  1.1187e-01,\n",
       "           4.6674e-01,  2.5707e-01, -1.0383e+00,  6.2382e-01,  2.9723e-01,\n",
       "          -3.8958e-02,  6.8466e-03,  9.7311e-01, -3.9276e-01, -3.8683e-01,\n",
       "          -1.0294e-01,  1.7673e-01,  5.0550e-02,  1.9353e-01,  1.8642e-02,\n",
       "          -4.5532e-01, -4.0325e-02,  2.4558e-02,  5.4511e-01, -6.8087e-01,\n",
       "          -5.9299e-01, -4.5284e-01, -4.9808e-01,  3.1780e-02,  2.2487e-01,\n",
       "          -5.4789e-01,  8.3545e-01, -6.2325e-01, -3.7478e-01, -1.5207e-01,\n",
       "           1.0117e-01,  9.3830e-02,  5.9769e-01,  5.3157e-01, -4.0447e-01,\n",
       "           7.4023e-02, -9.7771e-02,  1.1353e-01,  2.9111e-01,  5.1639e-02,\n",
       "           1.8927e-02, -4.2329e-01, -1.5507e-02,  3.4896e-02,  5.3655e-02,\n",
       "           1.3358e-01, -2.9661e-01,  1.3151e-01, -4.3889e-01,  9.0164e-03,\n",
       "           1.3168e-01, -3.5210e-01, -7.4252e-01,  1.0893e+00,  4.8899e-01,\n",
       "          -4.0396e-01,  4.6789e-01, -6.3856e-01,  5.8202e-02,  2.6576e-02,\n",
       "          -3.9449e-02,  1.5456e-01, -2.4896e-01, -5.1998e-01, -3.4591e-02,\n",
       "           2.7640e-01, -9.2318e-01, -5.0318e-01, -5.7892e-02, -1.2983e-01,\n",
       "           4.8855e-01, -7.5446e-01, -1.5824e-01, -4.1403e-03,  3.3032e-01,\n",
       "           2.6526e-01,  1.0341e-01, -7.7361e-02,  1.3914e-01, -1.0004e-01,\n",
       "          -3.3667e-01, -9.4172e-02, -5.3603e-01, -6.1599e-02, -9.2649e-02,\n",
       "          -5.6353e-01, -6.0563e-01, -1.3410e-01, -1.5688e-01, -4.3968e-01,\n",
       "          -3.4809e-01, -4.0729e-02,  2.9293e-01,  2.5163e-01,  3.3629e-01,\n",
       "           7.8863e-01,  8.1961e-01,  7.5193e-01,  1.0998e+00, -1.4506e-01,\n",
       "           5.9659e-01, -5.1275e-01,  1.4330e-01,  1.3790e-01, -7.8558e-01,\n",
       "           3.5962e-01, -9.2327e-02, -1.8226e-01, -2.5001e-01,  4.5758e-01,\n",
       "           3.0704e-01,  1.2518e-01,  5.9549e-02,  1.6984e-01, -5.4926e-01,\n",
       "          -1.4223e-02, -2.5400e-01, -5.8830e-01, -2.8315e-01,  2.4553e-01,\n",
       "          -3.5524e-01,  8.0769e-01, -7.6379e-02, -5.9787e-01,  1.6103e-01,\n",
       "          -3.3894e-01,  2.8237e-01,  4.2862e-01, -2.8031e-01,  5.3330e-01,\n",
       "           7.5079e-01,  1.8659e-01,  5.8158e-01,  5.3832e-01, -2.9063e-01,\n",
       "          -9.2984e-02,  7.8257e-02, -6.6729e-02, -6.7897e-03,  1.7805e-02,\n",
       "          -1.9336e-01, -9.4483e-02, -8.1526e-02,  2.3724e-01,  1.3469e-01,\n",
       "          -5.2066e-01, -3.1475e-01,  1.8558e-01, -6.1731e-01,  2.6190e-01,\n",
       "          -3.1629e-02,  7.1898e-01,  2.2374e-02, -8.3796e-01,  2.8798e-01,\n",
       "           8.8747e-01,  1.8220e-01, -2.4351e-01, -1.0167e-02,  5.9270e-01,\n",
       "           4.5432e-01,  7.2410e-02,  6.3993e-03, -1.0362e-01,  1.6974e-01,\n",
       "           5.6614e-01, -4.6515e-02,  1.5925e-01, -6.6424e-01,  1.9632e-01,\n",
       "           4.3174e-01, -8.4526e-02,  9.3160e-02, -7.9347e-01,  5.1429e-01,\n",
       "          -2.1815e-01, -5.2983e-02, -7.9144e-03,  1.0795e-01,  7.8699e-03,\n",
       "          -2.0660e-01, -4.5096e-01, -1.2059e-01,  5.6718e-01,  5.8870e-01,\n",
       "          -2.2514e-01, -1.4965e-01,  6.2865e-02,  1.0267e-01, -2.6246e-01,\n",
       "           6.4721e-01, -1.2572e-01,  1.6097e-01, -7.3799e-01,  2.9450e-01,\n",
       "          -5.2213e-01, -6.8186e-02, -1.0532e-01,  1.7195e-01,  4.1843e-01,\n",
       "           2.9625e-02, -3.3872e-01, -1.8699e-02, -9.6591e-02, -5.8393e-01,\n",
       "           2.9095e-01,  6.8223e-01,  3.3678e-01, -1.0582e-01, -8.1596e-01,\n",
       "          -3.3706e-01, -1.0704e-01,  7.0161e-01,  1.0056e-01, -3.3596e-01,\n",
       "          -9.0781e-01, -4.6621e-01, -7.9064e-02, -2.1240e-01,  3.5387e-01,\n",
       "          -7.5226e-01,  4.5250e-01,  1.8720e-01, -1.1137e-02, -9.6334e-02,\n",
       "           4.3866e-01, -3.2387e-02,  4.4667e-01,  2.3304e-02, -4.3880e-01,\n",
       "           3.8075e-01, -2.6942e-01, -3.3752e-02,  5.5334e-01, -6.2308e-02,\n",
       "          -1.8014e-01,  1.1077e-01,  7.6899e-02, -1.0206e+00,  6.8033e-01,\n",
       "          -5.3940e-01, -2.8469e-01,  7.3867e-01,  4.4554e-01, -5.8669e-01,\n",
       "          -8.2158e-03, -2.9027e-01,  2.1947e-01,  1.2961e-01, -5.3576e-03,\n",
       "          -1.9881e-01,  1.0518e-01,  9.5116e-01,  2.1692e-01,  5.6421e-02,\n",
       "          -7.6643e-02,  3.0253e-02,  2.1000e-01, -3.1455e-01,  4.7874e-01,\n",
       "           4.0256e-01, -5.0292e-01, -2.4395e-02,  5.2578e-01,  4.1265e-01,\n",
       "          -9.2552e-01,  4.2068e-01,  5.5013e-02, -5.5643e-01,  6.7235e-01,\n",
       "          -1.0616e-01,  5.5074e-01,  1.3365e-01,  2.0120e-01, -4.3594e-01,\n",
       "          -3.0606e-01,  9.7094e-02, -3.6516e-01, -6.1476e-01,  3.7301e-01,\n",
       "           3.5198e-01, -2.9184e-01, -5.0116e-01, -8.9859e-01,  2.3695e-01,\n",
       "          -2.1505e-01, -5.2697e-01,  2.1200e-01,  3.4088e-01, -4.3247e-01,\n",
       "           3.4168e-01, -4.1575e-01,  4.4513e-01,  1.7061e-01, -4.3313e-01,\n",
       "          -5.0540e-01,  4.3992e-02, -1.0268e-03, -4.0599e-01,  3.7353e-02,\n",
       "          -4.0061e-01,  3.5593e-02, -7.9209e-01, -1.0083e+00, -9.5072e-02,\n",
       "          -1.9914e-01, -6.4861e-01, -7.4568e-01,  3.7775e-01,  6.9575e-01,\n",
       "          -9.7829e-03, -2.3886e-02, -3.0238e-01, -4.4463e-01,  1.5674e-01,\n",
       "          -3.1571e-01,  7.2708e-01,  4.8615e-02,  6.6151e-02, -6.1270e-01,\n",
       "          -7.7176e-03, -3.8593e-01,  2.6109e-01, -4.8169e-01, -4.7062e-01,\n",
       "           2.3355e-01,  5.8889e-01, -4.7338e-01,  4.2386e-01, -2.7545e-01,\n",
       "          -3.6917e-01, -2.1415e-02,  5.1062e-01, -4.2315e-01, -2.8855e-01,\n",
       "           4.8412e-01,  3.4676e-01, -1.2257e-01, -2.7834e-01,  1.3186e-01,\n",
       "           1.1988e-04,  1.4893e-01, -6.7357e-01,  4.1977e-01,  8.3345e-01,\n",
       "           2.2404e-01, -7.8069e-02,  3.5552e-01, -3.2141e-01, -6.0300e-01,\n",
       "           1.6018e-01, -3.2947e-01,  9.0059e-01, -4.9447e-01, -2.2585e-02,\n",
       "           3.5372e-01,  1.0704e-01, -1.5539e-01, -4.3295e-01,  1.9143e-01,\n",
       "          -1.1988e-01,  3.4601e-01,  6.4017e-01, -6.3177e-01, -4.2457e-01,\n",
       "           3.0907e-01, -1.8660e-02, -1.4618e-01, -3.0567e-01,  8.4871e-01,\n",
       "          -1.5128e-01, -3.5856e-01, -2.4660e-01, -1.8246e-01, -4.9751e-01,\n",
       "           5.5468e-03,  4.3307e-01,  7.8740e-02, -3.3269e-01,  3.2587e-01,\n",
       "           9.5892e-02,  7.6453e-01, -5.7542e-01,  8.6201e-01,  1.2208e-01,\n",
       "           2.6063e-01, -4.5866e-01, -2.8601e-01, -3.3601e-01, -3.9178e-01,\n",
       "           4.7784e-01, -1.2852e-01,  1.1436e+00,  3.5709e-02,  2.8730e-01,\n",
       "          -1.1141e+00,  4.3757e-01,  5.7216e-02, -5.3069e-01,  1.5713e-01,\n",
       "           2.6877e-01,  2.7733e-01,  3.1365e-01,  7.5713e-01,  4.3284e-01,\n",
       "          -1.5862e-01,  1.1261e-01,  3.7226e-01, -8.5554e-02, -1.2953e-01,\n",
       "          -4.1819e-02,  2.6134e-01, -2.9488e-01,  8.5734e-01, -9.2528e-02,\n",
       "          -1.5215e-02,  2.6313e-01,  1.7808e-01,  2.5565e-01, -7.9551e-01,\n",
       "           5.4857e-01,  5.5651e-03, -3.2287e-03, -4.5516e-02,  1.1423e-01,\n",
       "          -7.0977e-01,  5.5780e-01, -3.1438e-01, -9.8873e-02, -4.1693e-02,\n",
       "           2.7888e-01]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.6114,  0.1041, -0.3909,  0.7535, -0.1721,  0.0511,  0.0193]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test prediction\n",
    "muzeronet.prediction(encoded_state=encoded_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 257, 6, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6114,  0.1041, -0.3909,  0.7535, -0.1721,  0.0511,  0.0193]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test network units\n",
    "muzeronet.recurrent_inference(encoded_state, action)\n",
    "muzeronet.initial_inference(image).policy_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muzeronet.from_support_to_scalar(muzeronet.initial_inference(image).reward, muzeronet.prediction_support_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.game import Game\n",
    "from typing import List\n",
    "\n",
    "MAXIMUM_FLOAT_VALUE = float(\"inf\")\n",
    "\n",
    "class MinMaxStats(object):\n",
    "  \"\"\"A class that holds the min-max values of the tree.\"\"\"\n",
    "\n",
    "  def __init__(self, known_bounds: Tuple = None):\n",
    "    assert known_bounds is None or len(known_bounds) == 2\n",
    "    self.maximum = known_bounds[1] if known_bounds else -MAXIMUM_FLOAT_VALUE\n",
    "    self.minimum = known_bounds[0] if known_bounds else MAXIMUM_FLOAT_VALUE\n",
    "\n",
    "  def update(self, value: float):\n",
    "    self.maximum = max(self.maximum, value)\n",
    "    self.minimum = min(self.minimum, value)\n",
    "\n",
    "  def normalize(self, value: float) -> float:\n",
    "    if self.maximum > self.minimum:\n",
    "      # We normalize only when we have set the maximum and minimum values.\n",
    "      return (value - self.minimum) / (self.maximum - self.minimum)\n",
    "    return value\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, prior: float):\n",
    "        self.visit_count = 0\n",
    "        self.player = None\n",
    "        self.prior = prior\n",
    "        self.value_sum = 0\n",
    "        self.children = {}\n",
    "        self.hidden_state = None\n",
    "        self.reward = 0\n",
    "\n",
    "    def expanded(self) -> bool:\n",
    "        return len(self.children) > 0\n",
    "\n",
    "    def value(self) -> float:\n",
    "        if self.visit_count == 0:\n",
    "           return 0\n",
    "        return self.value_sum / self.visit_count\n",
    "\n",
    "class MuZeroConfig:\n",
    "\n",
    "    def __init__(self, game_class, game_configs: dict = {},\n",
    "                 history_len = 7, max_moves = 30,\n",
    "                 root_dirichlet_alpha = 0.3, root_exploration_factor = 0.25,\n",
    "                 known_bounds = None, c1 = 1.25, c2 = 19.652, num_simulations = 100,\n",
    "                 discount = 0.99):\n",
    "        self.game_class = game_class\n",
    "        self.game_configs = game_configs\n",
    "\n",
    "        self.history_len = history_len\n",
    "        self.max_moves = max_moves\n",
    "        self.root_dirichlet_alpha = root_dirichlet_alpha\n",
    "        self.root_exploration_factor = root_exploration_factor\n",
    "        self.known_bounds = known_bounds\n",
    "        self.c1 = c1\n",
    "        self.c2 = c2\n",
    "        self.num_simulations = num_simulations\n",
    "        self.discount = discount\n",
    "\n",
    "    def new_game(self):\n",
    "        return Game(self.game_class(**self.game_configs), self.history_len) \n",
    "    \n",
    "    def temperature_value(self, num_counts: int) -> float:\n",
    "        if num_counts < self.max_moves:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "def play_game(config: MuZeroConfig, network: MuZeroNetwork) -> Game:\n",
    "    game = config.new_game()\n",
    "\n",
    "    while not game.terminal() and len(game.history) < config.max_moves:\n",
    "        # At the root of the search tree we use the representation function to\n",
    "        # obtain a hidden state given the current observation.\n",
    "        root = Node(0)\n",
    "        current_observation = game.make_image(-1)\n",
    "        expand_node(root, game.to_play(), game.action_mask(),\n",
    "                    network.from_output_to_scalar(network.initial_inference(current_observation), softmax=False))\n",
    "        add_exploration_noise(config, root)\n",
    "\n",
    "        # We then run a Monte Carlo Tree Search using only action sequences and the\n",
    "        # model learned by the network.\n",
    "        run_mcts(config, root, game.action_history(), game.to_play(), game.action_space(mask=True), network)\n",
    "        action = select_action(config, len(game.history), root, network)\n",
    "        game.step(action)\n",
    "        game.store_search_statistics(root)\n",
    "    return game\n",
    "    \n",
    "def expand_node(node: Node, player: str, action_mask: torch.Tensor, initial_inference: NetworkOutput):\n",
    "    node.player = player\n",
    "    node.hidden_state = initial_inference.hidden_state\n",
    "    node.reward = initial_inference.reward\n",
    "\n",
    "    with torch.no_grad():\n",
    "        action_probabilities = initial_inference.policy_logits.clone()\n",
    "        action_probabilities[action_mask.view(action_probabilities.shape[0], -1) == 0] = -MAXIMUM_FLOAT_VALUE\n",
    "        action_probabilities = torch.nn.functional.softmax(action_probabilities, dim=1)\n",
    "\n",
    "        for action in torch.arange(0, action_mask.shape[0])[action_mask==1]:\n",
    "            node.children[action] = Node(action_probabilities[:, action])\n",
    "\n",
    "def add_exploration_noise(config: MuZeroConfig, node: Node):\n",
    "    noise = np.random.dirichlet([config.root_dirichlet_alpha]*len(node.children)) * config.root_exploration_factor\n",
    "    for action in node.children.keys():\n",
    "        node[action].prior = (1-config.root_exploration_factor) * node[action].prior + noise[action]\n",
    "\n",
    "def run_mcts(config: MuZeroConfig, root: Node, action_history_global: List, player: str, full_action_mask: np.array, network: MuZeroNetwork):\n",
    "    min_max = MinMaxStats(config.known_bounds)\n",
    "\n",
    "    for _ in range(config.num_simulations):\n",
    "        # Selection\n",
    "        # Select the node based on a UCB formula\n",
    "        action_history = action_history_global.clone()\n",
    "        node = root\n",
    "        visited_childs: List[Node] = []\n",
    "        while node.expanded():\n",
    "            visited_childs.append(node)\n",
    "            action, node = select_child(config, node, min_max)\n",
    "            action_history.append(action)\n",
    "\n",
    "        # Expansion and Simulation\n",
    "        # Expand selected node\n",
    "        last_hidden_state = visited_childs[-1].hidden_state\n",
    "        network_output = network.from_output_to_scalar(network.recurrent_inference(last_hidden_state, action_history[-1]), softmax=False)\n",
    "        expand_node(node, player, full_action_mask, network_output)\n",
    "        visited_childs.append(node)\n",
    "\n",
    "        # Backpropagation\n",
    "        backpropagate(config, visited_childs, player, network_output.value)\n",
    "        \n",
    "def select_child(config: MuZeroConfig, node: Node, min_max: MinMaxStats):\n",
    "    # For each node, calculate ucb\n",
    "    _, action, child = max((ucb_score(config, node, child, min_max), action, child) for action, child in node.children.items())\n",
    "    return action, child\n",
    "\n",
    "def ucb_score(config: MuZeroConfig, parent: Node, node: Node, min_max: MinMaxStats):\n",
    "    probability_term = node.prior * np.sqrt(parent.visit_count) / (node.visit_count + 1)\n",
    "    probability_term *= config.c1 + np.log((parent.visit_count + config.c2 + 1) / config.c2)\n",
    "    return min_max.normalize(node.value()) + probability_term\n",
    "\n",
    "def backpropagate(config: MuZeroConfig, visited_childs: List, player: str, value: float, min_max: MinMaxStats):\n",
    "    for child in visited_childs[::-1]:\n",
    "        child.value_sum += value if child.to_play() == player else -value\n",
    "        child.visit_count += 1\n",
    "        min_max.update(child.value())\n",
    "\n",
    "        value = child.reward + config.discount * value\n",
    "\n",
    "def select_action(config: MuZeroConfig, num_actions: int, node: Node, network: MuZeroNetwork):\n",
    "    temperature = config.temperature_value(num_actions)\n",
    "    actions, counts = list(zip(*[(action, child.visit_count) for action, child in node.children.items()]))\n",
    "    counts = np.array(counts) ** 1/temperature\n",
    "    prob_distribution = counts / np.sum(counts)\n",
    "    return np.random.choice(actions, p=prob_distribution)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature = 1.0\n",
    "actions, counts= list(zip(*[(1,10),(2,30),(4,20)]))\n",
    "counts = np.array(counts) ** 1/temperature\n",
    "prob_distribution = counts / np.sum(counts)\n",
    "np.random.choice(actions, p=prob_distribution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
