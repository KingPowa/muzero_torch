{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym as g\n",
    "from gym import spaces\n",
    "from connect4 import *\n",
    "from envs import ConnectNEnv\n",
    "from networks.architecture import RepresentationNetwork, DynamicsNetwork, PredictionNetwork\n",
    "from architecture.game import Target\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.engine import *\n",
    "from architecture.network import MuZeroNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "muzeronet = MuZeroNetwork(3, 42, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2797, 0.3040, 0.9832, 0.9988, 0.3749, 0.7835, 0.3174],\n",
      "          [0.2785, 0.9220, 0.5011, 0.6089, 0.1654, 0.8720, 0.0912],\n",
      "          [0.9946, 0.6199, 0.9503, 0.0078, 0.0275, 0.2187, 0.7940],\n",
      "          [0.7271, 0.9436, 0.3944, 0.2669, 0.3033, 0.6880, 0.7317],\n",
      "          [0.3456, 0.3858, 0.1502, 0.1603, 0.3491, 0.1643, 0.3143],\n",
      "          [0.9120, 0.0264, 0.7435, 0.9332, 0.0969, 0.4670, 0.9831]],\n",
      "\n",
      "         [[0.3059, 0.2775, 0.7557, 0.7167, 0.1140, 0.6954, 0.2232],\n",
      "          [0.8256, 0.3419, 0.1594, 0.6122, 0.8190, 0.7771, 0.7111],\n",
      "          [0.7063, 0.8975, 0.7128, 0.8875, 0.4645, 0.6768, 0.2822],\n",
      "          [0.8053, 0.8893, 0.8285, 0.6905, 0.7734, 0.5998, 0.5583],\n",
      "          [0.2472, 0.6939, 0.1773, 0.2455, 0.5866, 0.6015, 0.4868],\n",
      "          [0.6315, 0.3113, 0.7685, 0.4551, 0.4608, 0.9445, 0.5995]],\n",
      "\n",
      "         [[0.6289, 0.5063, 0.9205, 0.0549, 0.2008, 0.5700, 0.7619],\n",
      "          [0.2182, 0.6626, 0.3760, 0.1435, 0.7542, 0.3110, 0.1492],\n",
      "          [0.3473, 0.7272, 0.8303, 0.4252, 0.8554, 0.4156, 0.3084],\n",
      "          [0.9581, 0.0117, 0.7913, 0.6258, 0.3494, 0.1408, 0.5659],\n",
      "          [0.6577, 0.5772, 0.7391, 0.7521, 0.8940, 0.8359, 0.1004],\n",
      "          [0.1458, 0.1728, 0.0620, 0.1817, 0.5126, 0.0248, 0.5099]]]])\n"
     ]
    }
   ],
   "source": [
    "# Test representation\n",
    "image = torch.rand((1,3,6,7))\n",
    "print(image)\n",
    "encoded_state = muzeronet.representation(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.]]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Test dynamics\n",
    "action = torch.Tensor([2]).view(1,1)\n",
    "print(action, action.shape)\n",
    "a: NetworkOutput = muzeronet.dynamics(encoded_state=encoded_state, action=action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.1049e-01,  1.3975e-01, -1.1045e-01, -8.5051e-01,  5.4529e-01,\n",
       "           4.1885e-01,  7.6424e-02,  6.0599e-01,  2.6680e-01,  3.4567e-01,\n",
       "           1.6376e-01, -1.2995e-01, -4.4439e-01,  5.0904e-02, -5.7539e-02,\n",
       "           1.9377e-01, -1.2343e-01, -5.5293e-01,  1.0115e-01, -1.4732e-01,\n",
       "           1.6315e-01, -6.1254e-01,  2.0189e-01, -3.5490e-01, -7.7985e-02,\n",
       "           4.9717e-01, -4.0054e-01, -1.1507e+00, -3.8067e-01,  1.8780e-01,\n",
       "          -3.0046e-01, -1.2041e-01, -3.9061e-01, -3.8826e-01,  1.0007e-01,\n",
       "           2.3968e-02, -4.9382e-01,  9.8615e-02, -1.0473e-01,  2.7974e-01,\n",
       "           2.2425e-01,  7.0073e-02,  6.6448e-01, -5.3587e-01,  9.3668e-01,\n",
       "          -3.3355e-01, -7.4464e-01,  1.7596e-01,  6.5505e-03, -2.6111e-01,\n",
       "           2.2988e-01, -1.0597e-01, -2.0222e-01, -1.1842e-01, -5.7459e-01,\n",
       "          -1.6419e-01,  1.2231e-03, -2.5197e-01,  2.2678e-01, -2.3397e-01,\n",
       "          -4.5855e-01,  1.4848e-02,  6.8383e-02, -3.3902e-01, -4.5281e-01,\n",
       "           6.6314e-01, -1.0576e-01,  3.8478e-01, -3.1486e-01,  2.1127e-01,\n",
       "           6.7030e-01, -3.6366e-01,  6.1949e-01,  9.1359e-01,  4.4855e-01,\n",
       "           8.0176e-02, -2.0737e-01, -1.1586e-01,  1.0313e-01, -4.3869e-01,\n",
       "          -1.1856e-01,  1.8231e-02,  1.1933e-01,  4.0072e-02,  2.7047e-01,\n",
       "           4.3223e-01, -1.4233e-01, -7.1505e-02,  3.8726e-03, -5.1544e-01,\n",
       "           2.0175e-01,  5.8702e-01, -4.2556e-01,  3.0234e-01, -4.8046e-01,\n",
       "           7.7708e-01,  5.9797e-01,  1.7316e-01,  5.2903e-01, -5.2112e-01,\n",
       "          -1.4254e-02, -3.1030e-01, -4.0873e-02, -3.7648e-01, -2.1618e-01,\n",
       "           2.7420e-01,  2.6699e-03,  6.4780e-01, -3.4107e-01,  7.9579e-02,\n",
       "          -1.6226e+00,  1.6127e-01,  6.8864e-01, -3.8954e-01, -4.8296e-01,\n",
       "           5.3300e-01,  5.9408e-01,  7.0716e-01, -6.4434e-02,  5.6691e-01,\n",
       "           2.5255e-01,  1.7069e-01,  1.4143e-03,  1.4630e-01,  9.4581e-02,\n",
       "           2.8792e-02,  1.3952e-01, -2.2902e-01,  6.4343e-01,  2.8313e-01,\n",
       "          -4.3054e-01, -6.1513e-01, -2.6556e-01, -7.6677e-01, -1.6472e-01,\n",
       "          -2.3121e-01,  2.0125e-01, -4.4761e-01,  4.7668e-01, -1.5130e-01,\n",
       "          -5.2821e-01, -2.3644e-01, -3.6703e-01, -1.5659e-01, -1.0068e-01,\n",
       "          -5.6795e-01, -4.5543e-01,  5.3335e-01, -5.0073e-04,  4.0177e-01,\n",
       "          -4.2157e-02, -2.7508e-01,  1.7246e-01, -2.1260e-01, -3.5082e-02,\n",
       "           1.6520e-01, -1.6224e-01, -4.8421e-01,  2.6737e-01,  6.1176e-01,\n",
       "          -3.6043e-01,  2.5976e-01, -2.4237e-02, -1.4090e-01,  1.3024e-01,\n",
       "          -3.0708e-02,  6.3349e-01,  5.1494e-02,  2.6907e-01, -1.1685e-01,\n",
       "          -4.6230e-01, -6.7323e-03,  8.6878e-02, -5.3495e-01,  6.5826e-01,\n",
       "          -2.6872e-01, -4.0180e-01, -1.4557e-01,  1.2380e-01,  3.9521e-01,\n",
       "          -3.1762e-01,  5.2023e-02,  8.0736e-01,  2.8886e-01, -1.6714e-01,\n",
       "           1.2178e+00,  2.7241e-01,  5.0396e-02,  6.7321e-02, -4.1330e-01,\n",
       "           3.7613e-01, -5.2171e-01,  3.9547e-01, -8.7511e-01,  3.7149e-01,\n",
       "           7.5891e-01, -2.4495e-01,  3.2452e-01, -9.7866e-01,  2.4031e-01,\n",
       "          -3.3020e-01,  4.5216e-01, -1.4151e-01, -1.5840e-01, -4.4967e-01,\n",
       "          -7.2775e-01,  1.6826e-01,  3.8750e-01,  4.2743e-01,  6.6208e-01,\n",
       "           3.3395e-01,  1.0097e-01, -1.6292e-01, -1.3460e-01, -3.9683e-01,\n",
       "          -7.4912e-01, -1.4853e-01,  3.7314e-01, -1.8328e-01, -4.1406e-01,\n",
       "           7.7040e-01,  4.4968e-01, -8.9120e-01,  7.1882e-02, -2.6906e-01,\n",
       "           3.6200e-01, -9.5647e-01, -2.0497e-01, -2.7038e-01,  3.9076e-01,\n",
       "          -2.1603e-01,  2.5682e-01,  3.0879e-02,  2.2316e-01, -1.3554e-01,\n",
       "          -2.2628e-01,  7.7055e-01,  5.6164e-01,  2.1525e-01, -3.0719e-01,\n",
       "          -7.6607e-01, -7.2184e-01,  1.7224e-01, -5.7221e-01, -7.2891e-01,\n",
       "          -3.7989e-01,  1.8203e-01, -6.9812e-01,  4.5816e-01,  2.7666e-01,\n",
       "           3.9661e-01, -6.3587e-01, -1.0210e-01, -3.0244e-01,  3.7565e-01,\n",
       "          -3.2423e-01, -5.9510e-01, -1.4433e-01,  4.3589e-01, -1.7505e-01,\n",
       "          -4.8480e-02, -1.0969e-01,  5.8796e-01,  8.8028e-02, -2.7850e-01,\n",
       "          -4.4032e-01, -4.5395e-01, -3.3835e-02,  3.6771e-01, -2.9549e-01,\n",
       "          -5.1872e-01, -1.0321e-01, -1.7547e-01, -6.3759e-01,  3.2645e-01,\n",
       "          -5.9479e-01, -3.0993e-01, -4.4696e-01,  6.3222e-01, -1.7341e-01,\n",
       "           5.8314e-01, -6.9140e-01, -3.5893e-01,  1.9745e-03,  6.0343e-02,\n",
       "          -3.1042e-01,  3.2548e-01, -5.7089e-02, -1.4663e+00, -2.7092e-01,\n",
       "          -1.8202e-01,  4.3971e-01, -6.7602e-01, -1.8649e-01, -4.5848e-01,\n",
       "           1.4532e-01,  1.4669e-01, -1.7473e-01,  2.0218e-02, -2.7381e-01,\n",
       "           4.0483e-01,  2.0343e-02,  5.2448e-01, -7.9117e-01,  1.3874e-01,\n",
       "           3.6566e-01,  5.2208e-01, -4.3920e-01,  4.5991e-01,  2.3368e-01,\n",
       "          -4.8302e-01, -4.1862e-02,  1.7320e-01, -2.1406e-02,  1.6680e-01,\n",
       "           2.1827e-02, -1.7410e-01,  4.2095e-03, -2.7337e-01,  4.3830e-03,\n",
       "          -2.5242e-01,  1.6589e-01, -9.4703e-02, -2.4800e-01, -2.8027e-01,\n",
       "           3.0419e-01,  6.4599e-01,  3.5175e-02,  1.0027e-01,  3.2547e-02,\n",
       "          -5.8827e-01, -2.9685e-01, -5.2964e-01, -5.7902e-01, -4.3361e-02,\n",
       "          -1.9738e-01, -7.0456e-01, -5.5646e-01,  1.8830e-02,  3.5458e-01,\n",
       "           5.4627e-01, -2.7343e-01,  1.1792e-01,  6.7464e-01,  1.2371e-01,\n",
       "          -5.3847e-01,  1.5218e-01,  2.5218e-01,  1.9619e-01, -5.8053e-03,\n",
       "           2.4329e-02,  4.7996e-01, -7.9421e-03,  2.1498e-01,  3.4516e-01,\n",
       "          -3.9662e-01,  4.8485e-01,  1.8827e-01,  1.4619e-01, -2.8767e-01,\n",
       "           2.5586e-01, -1.4714e-01, -1.6617e-01, -3.4923e-01, -5.6533e-01,\n",
       "           4.7683e-02, -2.3696e-01,  9.2305e-01,  1.4319e-01, -1.0435e-01,\n",
       "           7.8568e-02,  2.1894e-01,  1.4598e-01,  3.1555e-01, -2.4979e-01,\n",
       "           3.9498e-01, -2.1132e-01,  3.0554e-01, -2.0581e-01,  5.4902e-01,\n",
       "           1.4887e-01, -3.3799e-01, -9.9816e-02, -2.8273e-01,  4.4853e-01,\n",
       "          -1.2037e-01,  5.4057e-02, -8.9529e-01,  3.0907e-01, -1.0934e+00,\n",
       "          -2.9331e-01,  2.2811e-01, -9.7891e-02, -2.7909e-01,  1.4413e-01,\n",
       "           5.9886e-02,  5.8420e-01, -2.7277e-01, -2.2591e-01,  4.3748e-01,\n",
       "           4.2614e-01, -4.5392e-02,  3.7376e-01, -8.1189e-02,  5.1494e-01,\n",
       "           2.7888e-01, -7.5001e-01,  1.2763e-02, -1.5605e-01, -8.6525e-02,\n",
       "          -5.5044e-02, -2.8712e-01,  9.7537e-01,  1.7826e-01,  7.7002e-02,\n",
       "           1.0155e+00, -1.1419e-01, -4.0664e-01,  2.4979e-01, -3.5208e-01,\n",
       "           3.0389e-01, -2.9197e-01,  5.8863e-01, -2.2153e-01, -1.1279e-01,\n",
       "          -2.8792e-01, -3.0477e-02, -3.4468e-02,  1.0340e-02, -1.5722e-01,\n",
       "           6.0091e-01, -6.0887e-01,  1.9513e-01, -1.2381e-01, -7.5443e-01,\n",
       "           6.6859e-01,  5.0634e-01,  5.8055e-01,  4.1383e-01, -1.2734e-01,\n",
       "          -1.2462e-01, -1.3970e-01, -3.0764e-01,  4.5583e-01,  6.5551e-01,\n",
       "          -2.8595e-01,  4.0333e-01,  2.9079e-01, -3.2778e-01, -2.6770e-01,\n",
       "          -1.1550e-01,  7.4932e-01, -3.0743e-01, -5.2630e-01, -4.6461e-01,\n",
       "          -1.6863e-01,  4.5800e-01, -2.0481e-01,  7.9098e-01,  3.5602e-01,\n",
       "          -4.4565e-01, -6.3758e-01, -4.2977e-01, -5.0555e-01,  4.0970e-01,\n",
       "          -7.7389e-02,  4.3079e-01,  8.7117e-01, -2.9225e-01,  4.9991e-01,\n",
       "           3.4446e-01, -1.7725e-01,  1.6714e-01, -4.8096e-01,  2.0033e-01,\n",
       "          -6.8230e-01, -2.0583e-01,  3.9641e-01,  6.4660e-02,  6.5722e-01,\n",
       "           3.2751e-02,  4.0784e-01,  1.7410e-01,  7.5282e-02,  4.3311e-02,\n",
       "          -7.4057e-02,  6.1548e-02,  3.8089e-03,  7.3765e-01,  2.5194e-01,\n",
       "           2.0405e-01, -1.1595e-01, -2.3146e-01, -1.6356e-01,  2.1073e-01,\n",
       "          -5.2401e-01, -8.3216e-02,  2.6478e-01,  2.4160e-01,  2.6047e-01,\n",
       "           2.3361e-01,  5.4048e-02,  2.6551e-01, -4.1362e-01, -8.8916e-02,\n",
       "          -4.8082e-01,  5.3889e-01, -6.3577e-01, -5.4703e-01, -3.0851e-01,\n",
       "           2.0758e-01, -1.6123e-01,  3.3757e-01,  5.4906e-02,  2.8674e-01,\n",
       "           5.0063e-01, -1.6434e-01,  4.5786e-01, -1.0381e-01,  7.0550e-01,\n",
       "          -1.3679e-01,  7.1229e-02,  3.1887e-01,  5.7352e-01, -3.8914e-01,\n",
       "          -8.5870e-02,  3.1879e-01, -3.6115e-01, -2.8870e-01,  5.3697e-01,\n",
       "           1.4479e-01, -1.3765e-01, -1.0734e-01, -7.2598e-02, -2.0029e-01,\n",
       "          -2.8650e-01, -2.3595e-01,  3.5023e-01, -6.9656e-02, -2.7909e-01,\n",
       "           2.3925e-01, -1.7625e-01, -2.6592e-01,  5.1566e-01,  4.3385e-01,\n",
       "          -7.8408e-02,  4.9548e-02, -6.0643e-01,  4.3669e-02, -3.9015e-01,\n",
       "           5.3978e-01, -8.3702e-01, -4.0760e-01, -3.8012e-01,  4.8649e-01,\n",
       "          -8.1331e-02, -2.5554e-01, -4.7084e-02, -1.4138e-01, -7.5904e-02,\n",
       "           9.6997e-02, -3.1706e-01,  4.5991e-01, -7.0646e-01,  1.3865e-01,\n",
       "          -1.7632e-01, -3.9466e-01, -3.5054e-02,  8.1949e-01,  9.8715e-01,\n",
       "           1.5780e-01,  2.7905e-01, -6.4696e-01,  1.1391e-01, -4.4691e-01,\n",
       "           4.0009e-01,  4.7639e-01, -2.5559e-01, -4.2995e-01,  2.8766e-01,\n",
       "          -2.0530e-01, -3.3210e-01,  5.7728e-02, -4.0663e-01, -5.2214e-02,\n",
       "           2.0941e-01, -3.9773e-01, -4.7077e-01, -5.6958e-01,  5.3241e-02,\n",
       "           4.1657e-01,  2.6305e-01, -3.1499e-01,  1.2370e-01, -3.2480e-01,\n",
       "          -3.5458e-01, -4.0656e-01,  1.7838e-01, -2.1062e-01, -4.9820e-02,\n",
       "          -5.2833e-01]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.7461,  0.8230,  0.1014,  0.2588, -1.0727, -0.1451, -0.1464]],\n",
       "        grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test prediction\n",
    "muzeronet.prediction(encoded_state=encoded_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test network units\n",
    "ri = muzeronet.recurrent_inference(encoded_state, action)\n",
    "ii = muzeronet.initial_inference(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ri.policy_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muzeronet.from_support_to_scalar(muzeronet.initial_inference(image).reward, muzeronet.prediction_support_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing MinMax\n",
    "\n",
    "minmax = MinMaxStats((1,3)) # minmax = MinMaxStats()\n",
    "minmax.normalize(10)\n",
    "# minmax.update(1)\n",
    "# minmax.update(3)\n",
    "minmax.normalize(190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing Muzero config\n",
    "from envs import ConnectNEnv\n",
    "\n",
    "muzeroconfig = MuZeroConfig(ConnectNEnv, {})\n",
    "muzeroconfig.new_game()\n",
    "muzeroconfig.temperature_value(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing atomic functions\n",
    "node = Node(0)\n",
    "node1 = Node(0)\n",
    "node1.visit_count = 10\n",
    "node2 = Node(0.1)\n",
    "node2.visit_count = 20\n",
    "node.children = {1: node1, 2: node2}\n",
    "select_action(muzeroconfig, 20, node, muzeronet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation finished. Current game history 0.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 1.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || ||1|||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 2.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || ||2|| || ||1|||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 3.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || ||2|| ||1||1|||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 4.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || ||2||2|| ||1||1|||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 5.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || ||1|||\n",
      "||---------------------||\n",
      "||| || ||2||2|| ||1||1|||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 6.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || ||2|||\n",
      "||---------------------||\n",
      "||| || || || || || ||1|||\n",
      "||---------------------||\n",
      "||| || ||2||2|| ||1||1|||\n",
      "ooooooooooooooooooooooooo\n",
      "Simulation finished. Current game history 7.\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || || |||\n",
      "||---------------------||\n",
      "||| || || || || || ||1|||\n",
      "||---------------------||\n",
      "||| || || || || || ||2|||\n",
      "||---------------------||\n",
      "||| || || || || || ||1|||\n",
      "||---------------------||\n",
      "||| || ||2||2|| ||1||1|||\n",
      "ooooooooooooooooooooooooo\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01marchitecture\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MuZeroConnectN\n\u001b[1;32m      3\u001b[0m muzeronet \u001b[38;5;241m=\u001b[39m MuZeroConnectN()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mplay_game\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmuzeroconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmuzeronet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/app/muzero_torch/architecture/engine.py:110\u001b[0m, in \u001b[0;36mplay_game\u001b[0;34m(config, network)\u001b[0m\n\u001b[1;32m    106\u001b[0m add_exploration_noise(config, root)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# We then run a Monte Carlo Tree Search using only action sequences and the\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# model learned by the network.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m \u001b[43mrun_mcts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_play\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation finished. Current game history \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(game\u001b[38;5;241m.\u001b[39mlength_of_history()))\n\u001b[1;32m    113\u001b[0m game\u001b[38;5;241m.\u001b[39mpresent_game()\n",
      "File \u001b[0;32m/app/muzero_torch/architecture/engine.py:156\u001b[0m, in \u001b[0;36mrun_mcts\u001b[0;34m(config, root, action_history_global, player, full_action_mask, network)\u001b[0m\n\u001b[1;32m    154\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m visited_childs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mhidden_state\n\u001b[1;32m    155\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([action_history[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 156\u001b[0m network_output \u001b[38;5;241m=\u001b[39m network\u001b[38;5;241m.\u001b[39mfrom_output_to_scalar(\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurrent_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlast_hidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m, softmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    157\u001b[0m expand_node(node, player, torch\u001b[38;5;241m.\u001b[39mTensor(full_action_mask), network_output)\n\u001b[1;32m    158\u001b[0m visited_childs\u001b[38;5;241m.\u001b[39mappend(node)\n",
      "File \u001b[0;32m/app/muzero_torch/architecture/network.py:165\u001b[0m, in \u001b[0;36mMuZeroNetwork.recurrent_inference\u001b[0;34m(self, hidden_state, action)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecurrent_inference\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_state: torch\u001b[38;5;241m.\u001b[39mTensor, action: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NetworkOutput:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# dynamics + prediction function\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     next_state, logits_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     logits_value, logits_policy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction(next_state)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NetworkOutput(logits_value, logits_reward, logits_policy, next_state)\n",
      "File \u001b[0;32m/app/muzero_torch/architecture/network.py:135\u001b[0m, in \u001b[0;36mMuZeroNetwork.dynamics\u001b[0;34m(self, encoded_state, action)\u001b[0m\n\u001b[1;32m    132\u001b[0m encoded_action \u001b[38;5;241m=\u001b[39m encoded_action\u001b[38;5;241m.\u001b[39mto(action\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    133\u001b[0m encoded_full_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((encoded_state, encoded_action), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m state_representation, logits_reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamics_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_full_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m orig_shape \u001b[38;5;241m=\u001b[39m state_representation\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Scale image along each channel\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/muzero_torch/networks/architecture.py:16\u001b[0m, in \u001b[0;36mDynamicsNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     15\u001b[0m     next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_net(x)\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m next_state, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward_predictor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/app/muzero_torch/networks/common.py:72\u001b[0m, in \u001b[0;36mContinousValuePredictor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m     x \u001b[38;5;241m=\u001b[39m conv(x)\n\u001b[1;32m     71\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_size)\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from architecture.network import MuZeroConnectN\n",
    "\n",
    "muzeronet = MuZeroConnectN()\n",
    "play_game(muzeroconfig, muzeronet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from architecture.replay import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import softmax, cross_entropy\n",
    "\n",
    "class MuZero:\n",
    "\n",
    "    def __init__(self, config: MuZeroConfig):\n",
    "        self.steps = 0\n",
    "        self.config = config\n",
    "        self.network = self.load_network()\n",
    "\n",
    "    def execute(self):\n",
    "        replay_buffer = ReplayBuffer(self.config.max_buffer_size, self.config.batch_size)\n",
    "\n",
    "        while True:\n",
    "            for _ in range(2):\n",
    "                self.self_play(replay_buffer)\n",
    "            self.train_model(replay_buffer)\n",
    "\n",
    "    def self_play(self, replay_buffer: ReplayBuffer):\n",
    "        network = self.get_latest_network()\n",
    "        game = play_game(self.config, network)\n",
    "        replay_buffer.add_game(game)\n",
    "\n",
    "    def train_model(self, replay_buffer: ReplayBuffer):\n",
    "        network = self.get_latest_network()\n",
    "        optimizer = torch.optim.SGD(network.parameters(), lr=self.config.lr, momentum=self.config.momentum)\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=self.config.decaying_func())\n",
    "\n",
    "        for i in self.config.training_steps:\n",
    "            if i%self.config.step_for_saving == 0:\n",
    "                self.save_network()\n",
    "            batch = replay_buffer.sample_batch(self.config.unroll_steps, self.config.td_steps)\n",
    "            self.update_weights(batch, optimizer, network, scheduler)\n",
    "\n",
    "    def update_weights(self, batch: List[Tuple[Tensor, List, List]], optimizer: torch.optim.Optimizer, network: MuZeroNetwork, scheduler: torch.optim.lr_scheduler.LRScheduler = None):\n",
    "\n",
    "        loss = 0\n",
    "        for image, actions, targets in batch:\n",
    "            value, reward, policy_logits, hidden_state = network.initial_inference(image).unpack()\n",
    "            # Grab all predictions as a tuple of: \n",
    "            # - gradient_scale (based on the number of actions)\n",
    "            # - predicted value\n",
    "            # - predicted logits\n",
    "            # - predicted reward\n",
    "            predictions: List[Tuple[float, Tensor, Tensor, Tensor]] = [(1.0, value, policy_logits, reward)]\n",
    "\n",
    "            for action in actions:\n",
    "                value, reward, policy_logits, hidden_state = network.recurrent_inference(hidden_state=hidden_state, action=action).unpack()\n",
    "\n",
    "                # Scale the gradient\n",
    "                predictions.append((1.0/len(actions), value, policy_logits, reward))\n",
    "                # Adjust hidden_state gradient\n",
    "                hidden_state = ut.scale_torch_gradient(hidden_state, self.config.gradient_scale_factor)\n",
    "\n",
    "            for pred, target in zip(predictions, targets):\n",
    "\n",
    "                l = self.calculate_loss(pred, target, network)\n",
    "                loss += l\n",
    "\n",
    "        for weight in network.parameters():\n",
    "            loss = self.config.weight_decay * weight.norm()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    def calculate_loss(self, pred: List[Tuple[float, Tensor, Tensor, Tensor]], target: Target, network: MuZeroNetwork):\n",
    "        scaling_factor, value, policy_logits, reward = pred\n",
    "        t_target_value, t_target_reward, softmaxed_t_target_policy = network.from_target_to_support(target)\n",
    "        \n",
    "        softmaxed_value_logits = softmax(value, dim=1)\n",
    "        softmaxed_reward_logits = softmax(reward, dim=1)\n",
    "        softmaxed_policy_logits = softmax(policy_logits, dim=1)\n",
    "        softmaxed_t_target_value = softmax(t_target_value, dim=1)\n",
    "        softmaxed_t_target_reward = softmax(t_target_reward, dim=1)\n",
    "\n",
    "        lv = cross_entropy(softmaxed_value_logits, softmaxed_t_target_value, reduction=\"sum\")\n",
    "        lr = cross_entropy(softmaxed_reward_logits, softmaxed_t_target_reward, reduction=\"sum\")\n",
    "        la = cross_entropy(softmaxed_policy_logits, softmaxed_t_target_policy, reduction=\"sum\")\n",
    "\n",
    "        return ut.scale_torch_gradient(lv + lr + la, scaling_factor)\n",
    "\n",
    "    def get_latest_network(self):\n",
    "        network = MuZeroConnectN()\n",
    "        self.load_network(network)\n",
    "        return network\n",
    "        \n",
    "    def load_network(self, network: MuZeroNetwork):\n",
    "        loaded_nets = network.load_network()\n",
    "\n",
    "    def save_network(self, network: MuZeroNetwork):\n",
    "        network.save_network()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
